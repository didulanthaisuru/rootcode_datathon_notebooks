{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# üìä EMPLOYEE PREDICTION MODEL\n",
    "# Complete Pipeline: Task Time Forecasting ‚Üí Employee Count Prediction\n",
    "# ===============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ EMPLOYEE PREDICTION MODEL - COMPLETE PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===============================\n",
    "# üîß CONFIGURATION PARAMETERS\n",
    "# ===============================\n",
    "# Section-specific Prophet hyperparameters (tune these later)\n",
    "PROPHET_PARAMS = {\n",
    "    'SEC-001': {\n",
    "        'changepoint_prior_scale': 0.0038528202328995736,\n",
    "        'seasonality_prior_scale': 0.010042907896207173,\n",
    "        'fourier_order_monthly': 5,\n",
    "        'fourier_order_quarterly': 3\n",
    "    },\n",
    "    'SEC-002': {\n",
    "        'changepoint_prior_scale': 0.002641088178737233,\n",
    "        'seasonality_prior_scale': 20.215080462372438,\n",
    "        'fourier_order_monthly': 3,\n",
    "        'fourier_order_quarterly': 2\n",
    "    },\n",
    "    'SEC-003': {\n",
    "        'changepoint_prior_scale': 0.004970363760550267,\n",
    "        'seasonality_prior_scale': 0.6118755196634571,\n",
    "        'fourier_order_monthly': 7,\n",
    "        'fourier_order_quarterly': 4\n",
    "    },\n",
    "    'SEC-004': {\n",
    "        'changepoint_prior_scale': 0.0033372859157028488,\n",
    "        'seasonality_prior_scale': 0.7749723410793167,\n",
    "        'fourier_order_monthly': 5,\n",
    "        'fourier_order_quarterly': 3\n",
    "    },\n",
    "    'SEC-005': {\n",
    "        'changepoint_prior_scale': 0.07434427916859573,\n",
    "        'seasonality_prior_scale': 0.010009844767505318,\n",
    "        'fourier_order_monthly': 3,\n",
    "        'fourier_order_quarterly': 2\n",
    "    },\n",
    "    'SEC-006': {\n",
    "        'changepoint_prior_scale': 0.002026015292473149,\n",
    "        'seasonality_prior_scale': 0.029362473848920344,\n",
    "        'fourier_order_monthly': 5,\n",
    "        'fourier_order_quarterly': 3\n",
    "    }\n",
    "}\n",
    "\n",
    "# Default parameters (fallback for any missing sections)\n",
    "DEFAULT_PROPHET_PARAMS = {\n",
    "    'changepoint_prior_scale': 0.05,\n",
    "    'seasonality_prior_scale': 8.0,\n",
    "    'fourier_order_monthly': 5,\n",
    "    'fourier_order_quarterly': 3\n",
    "}\n",
    "\n",
    "# Model parameters\n",
    "HUBER_EPSILON = 1.35\n",
    "REGRESSION_WEIGHT_THRESHOLD = 0.9  # R¬≤ threshold for regression weight\n",
    "REGRESSION_WEIGHT_HIGH = 0.8       # Weight when R¬≤ > threshold\n",
    "REGRESSION_WEIGHT_LOW = 0.6        # Weight when R¬≤ <= threshold\n",
    "\n",
    "print(\"üìã CONFIGURATION:\")\n",
    "print(\"   Section-specific Prophet Parameters:\")\n",
    "for section, params in PROPHET_PARAMS.items():\n",
    "    print(f\"   {section}: CPS={params['changepoint_prior_scale']}, SPS={params['seasonality_prior_scale']}, \"\n",
    "          f\"Monthly={params['fourier_order_monthly']}, Quarterly={params['fourier_order_quarterly']}\")\n",
    "print(f\"   Default fallback parameters available for new sections\")\n",
    "\n",
    "# ===============================\n",
    "# üìÇ BLOCK 1: DATA LOADING & PREPROCESSING\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìÇ BLOCK 1: DATA LOADING & PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: Raw CSV file\n",
    "print(\"üì• INPUT: final_df_binary.csv\")\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('final_df_binary.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Feature engineering\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "df['is_working_day'] = ((df['is_holiday'] == 0) & (df['is_weekend'] == 0)).astype(int)\n",
    "\n",
    "# Train-Test Split\n",
    "train_data = df[df['year'] <= 2023].copy()\n",
    "test_data = df[df['year'] == 2024].copy()\n",
    "\n",
    "print(\"üìä DATA OVERVIEW:\")\n",
    "print(f\"   Total records: {len(df):,}\")\n",
    "print(f\"   Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"   Sections: {df['section_id'].nunique()}\")\n",
    "print(f\"   Training data: {len(train_data):,} records (2021-2023)\")\n",
    "print(f\"   Test data: {len(test_data):,} records (2024)\")\n",
    "\n",
    "# Output: Preprocessed DataFrames\n",
    "print(\"\\nüì§ OUTPUT DataFrames:\")\n",
    "print(\"   - train_data: Training dataset (2021-2023)\")\n",
    "print(\"   - test_data: Test dataset (2024)\")\n",
    "print(\"   - df: Complete preprocessed dataset\")\n",
    "\n",
    "print(f\"\\nüîç SAMPLE DATA:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# ===============================\n",
    "# üìà BLOCK 2: TRAINING DATA ANALYSIS\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà BLOCK 2: TRAINING DATA ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: train_data DataFrame\n",
    "print(\"üì• INPUT: train_data (2021-2023 data)\")\n",
    "\n",
    "working_train = train_data[train_data['is_working_day'] == 1]\n",
    "\n",
    "print(\"üìä CORRELATION ANALYSIS (Employee vs Task Time):\")\n",
    "correlations = {}\n",
    "correlation_results = []\n",
    "\n",
    "for section in working_train['section_id'].unique():\n",
    "    section_data = working_train[working_train['section_id'] == section]\n",
    "    if len(section_data) > 20:\n",
    "        corr = section_data['employees_on_duty'].corr(section_data['total_task_time_minutes'])\n",
    "        correlations[section] = corr\n",
    "        correlation_results.append({\n",
    "            'section_id': section,\n",
    "            'correlation': corr,\n",
    "            'data_points': len(section_data)\n",
    "        })\n",
    "        print(f\"   {section}: {corr:.3f} ({len(section_data)} data points)\")\n",
    "\n",
    "# Create correlation DataFrame\n",
    "correlation_df = pd.DataFrame(correlation_results)\n",
    "\n",
    "print(f\"\\nüìà TRAINING STATISTICS BY SECTION:\")\n",
    "stats = working_train.groupby('section_id').agg({\n",
    "    'employees_on_duty': ['count', 'mean', 'std', 'min', 'max'],\n",
    "    'total_task_time_minutes': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "training_stats = []\n",
    "for section in stats.index:\n",
    "    emp_stats = stats.loc[section, 'employees_on_duty']\n",
    "    task_stats = stats.loc[section, 'total_task_time_minutes']\n",
    "    \n",
    "    training_stats.append({\n",
    "        'section_id': section,\n",
    "        'working_days': emp_stats['count'],\n",
    "        'emp_mean': emp_stats['mean'],\n",
    "        'emp_std': emp_stats['std'],\n",
    "        'emp_min': emp_stats['min'],\n",
    "        'emp_max': emp_stats['max'],\n",
    "        'task_mean': task_stats['mean'],\n",
    "        'task_std': task_stats['std']\n",
    "    })\n",
    "    \n",
    "    print(f\"   {section}:\")\n",
    "    print(f\"      Working days: {emp_stats['count']:.0f}\")\n",
    "    print(f\"      Employees: {emp_stats['mean']:.1f} ¬± {emp_stats['std']:.1f} (range: {emp_stats['min']:.0f}-{emp_stats['max']:.0f})\")\n",
    "    print(f\"      Task time: {task_stats['mean']:.0f} ¬± {task_stats['std']:.0f} minutes\")\n",
    "\n",
    "# Create training statistics DataFrame\n",
    "training_stats_df = pd.DataFrame(training_stats)\n",
    "\n",
    "# Output: Analysis DataFrames\n",
    "print(\"\\nüì§ OUTPUT DataFrames:\")\n",
    "print(\"   - correlation_df: Correlation between employees and task time by section\")\n",
    "print(\"   - training_stats_df: Comprehensive training statistics by section\")\n",
    "print(\"   - working_train: Filtered training data (working days only)\")\n",
    "\n",
    "# ===============================\n",
    "# ü§ñ BLOCK 3: EMPLOYEE REGRESSION MODELS\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ü§ñ BLOCK 3: EMPLOYEE REGRESSION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: working_train DataFrame\n",
    "print(\"üì• INPUT: working_train (working days training data)\")\n",
    "\n",
    "employee_models = {}\n",
    "regression_results = []\n",
    "\n",
    "print(\"üî® BUILDING REGRESSION MODELS (Task Time ‚Üí Employee Count):\")\n",
    "\n",
    "for section in working_train['section_id'].unique():\n",
    "    section_data = working_train[working_train['section_id'] == section]\n",
    "\n",
    "    if len(section_data) > 30:\n",
    "        # Prepare regression data\n",
    "        X = section_data[['total_task_time_minutes']].values\n",
    "        y = section_data['employees_on_duty'].values\n",
    "\n",
    "        # Build Huber Regression model\n",
    "        model = HuberRegressor(epsilon=HUBER_EPSILON)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # Calculate efficiency metrics\n",
    "        valid_data = section_data[section_data['employees_on_duty'] > 0].copy()\n",
    "        valid_data['task_per_emp'] = valid_data['total_task_time_minutes'] / valid_data['employees_on_duty']\n",
    "\n",
    "        # Store model information\n",
    "        r2_score_val = model.score(X, y)\n",
    "        \n",
    "        employee_models[section] = {\n",
    "            'regression_model': model,\n",
    "            'avg_task_per_employee': valid_data['task_per_emp'].median(),\n",
    "            'min_employees': section_data['employees_on_duty'].min(),\n",
    "            'max_employees': section_data['employees_on_duty'].max(),\n",
    "            'training_r2': r2_score_val\n",
    "        }\n",
    "\n",
    "        regression_results.append({\n",
    "            'section_id': section,\n",
    "            'r2_score': r2_score_val,\n",
    "            'avg_efficiency': valid_data['task_per_emp'].median(),\n",
    "            'min_employees': section_data['employees_on_duty'].min(),\n",
    "            'max_employees': section_data['employees_on_duty'].max(),\n",
    "            'training_samples': len(section_data)\n",
    "        })\n",
    "\n",
    "        print(f\"   {section}: R¬≤ = {r2_score_val:.3f}, Avg efficiency = {valid_data['task_per_emp'].median():.1f} min/emp\")\n",
    "\n",
    "# Create regression results DataFrame\n",
    "regression_results_df = pd.DataFrame(regression_results)\n",
    "\n",
    "# Output: Models and results\n",
    "print(f\"\\nüì§ OUTPUT:\")\n",
    "print(f\"   - employee_models: Dictionary with {len(employee_models)} trained regression models\")\n",
    "print(\"   - regression_results_df: Regression performance metrics by section\")\n",
    "\n",
    "print(f\"\\nüîç REGRESSION SUMMARY:\")\n",
    "print(regression_results_df.round(2))\n",
    "\n",
    "# ===============================\n",
    "# üîÆ BLOCK 4: PROPHET TASK TIME FORECASTING\n",
    "# ===============================\n",
    "# üîÆ BLOCK 4: PROPHET TASK TIME FORECASTING (with regressors)\n",
    "# ===============================\n",
    "task_forecasts = {}\n",
    "task_time_models = {}\n",
    "prophet_results = []\n",
    "\n",
    "print(\"üìä FORECASTING 2024 TASK TIME WITH PROPHET (including regressors)...\")\n",
    "\n",
    "for section in working_train['section_id'].unique():\n",
    "    print(f\"   Forecasting {section}...\")\n",
    "    section_data = working_train[working_train['section_id'] == section].copy()\n",
    "\n",
    "    if len(section_data) < 50:\n",
    "        print(f\"      ‚ö†Ô∏è  Insufficient training data ({len(section_data)} records)\")\n",
    "        continue\n",
    "\n",
    "    # Prepare Prophet DataFrame\n",
    "    prophet_df = section_data[['date', 'total_task_time_minutes', 'is_weekend', 'is_holiday']].copy()\n",
    "    prophet_df.columns = ['ds', 'y', 'is_weekend', 'is_holiday']\n",
    "    prophet_df = prophet_df.sort_values('ds')\n",
    "\n",
    "    # Section-specific parameters or fallback\n",
    "    section_params = PROPHET_PARAMS.get(section, DEFAULT_PROPHET_PARAMS)\n",
    "    \n",
    "    # Build Prophet model\n",
    "    model = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=False,\n",
    "        changepoint_prior_scale=section_params['changepoint_prior_scale'],\n",
    "        seasonality_prior_scale=section_params['seasonality_prior_scale']\n",
    "    )\n",
    "\n",
    "    # Add custom seasonalities\n",
    "    model.add_seasonality(name='monthly', period=30.5, fourier_order=section_params['fourier_order_monthly'])\n",
    "    model.add_seasonality(name='quarterly', period=91.25, fourier_order=section_params['fourier_order_quarterly'])\n",
    "    \n",
    "    # Add regressors\n",
    "    model.add_regressor('is_weekend', prior_scale=0.5)  # Tuneable: adjust prior_scale\n",
    "    model.add_regressor('is_holiday', prior_scale=1.0)  # Tuneable: adjust prior_scale\n",
    "\n",
    "    # Fit model with regressors\n",
    "    model.fit(prophet_df[['ds', 'y', 'is_weekend', 'is_holiday']])\n",
    "\n",
    "    # Prepare test dates with regressors\n",
    "    test_working = test_data[(test_data['section_id'] == section) & (test_data['is_working_day'] == 1)].copy()\n",
    "    if len(test_working) > 0:\n",
    "        future_df = test_working[['date', 'is_weekend', 'is_holiday']].copy()\n",
    "        future_df.columns = ['ds', 'is_weekend', 'is_holiday']\n",
    "        forecast = model.predict(future_df)\n",
    "        forecast['yhat'] = forecast['yhat'].clip(lower=0)\n",
    "\n",
    "        task_forecasts[section] = {\n",
    "            'dates': future_df['ds'].values,\n",
    "            'predictions': forecast['yhat'].values\n",
    "        }\n",
    "        task_time_models[section] = model\n",
    "\n",
    "        # Training MAE\n",
    "        train_forecast = model.predict(prophet_df[['ds', 'is_weekend', 'is_holiday']])\n",
    "        train_mae = mean_absolute_error(prophet_df['y'], train_forecast['yhat'])\n",
    "\n",
    "        prophet_results.append({\n",
    "            'section_id': section,\n",
    "            'training_samples': len(prophet_df),\n",
    "            'forecast_days': len(future_df),\n",
    "            'train_mae': train_mae,\n",
    "            'avg_predicted_task_time': forecast['yhat'].mean(),\n",
    "            'changepoint_prior_scale': section_params['changepoint_prior_scale'],\n",
    "            'seasonality_prior_scale': section_params['seasonality_prior_scale'],\n",
    "            'fourier_monthly': section_params['fourier_order_monthly'],\n",
    "            'fourier_quarterly': section_params['fourier_order_quarterly'],\n",
    "            'regressor_weekend_prior': 0.5,\n",
    "            'regressor_holiday_prior': 1.0\n",
    "        })\n",
    "        \n",
    "        print(f\"      ‚Üí Forecasted {len(future_df)} days (MAE: {train_mae:.1f})\")\n",
    "\n",
    "              f\"CPS: {section_params['changepoint_prior_scale']}, SPS: {section_params['seasonality_prior_scale']})\")\n",
    "\n",
    "# Create Prophet results DataFrame\n",
    "prophet_results_df = pd.DataFrame(prophet_results)\n",
    "\n",
    "# Output: Forecasts and models\n",
    "print(f\"\\nüì§ OUTPUT:\")\n",
    "print(f\"   - task_forecasts: Dictionary with {len(task_forecasts)} section forecasts\")\n",
    "print(f\"   - task_time_models: Dictionary with {len(task_time_models)} trained Prophet models\")\n",
    "print(\"   - prophet_results_df: Prophet forecasting performance by section\")\n",
    "\n",
    "print(f\"\\nüîç PROPHET FORECAST SUMMARY:\")\n",
    "print(prophet_results_df.round(2))\n",
    "\n",
    "# ===============================\n",
    "# üîÑ BLOCK 5: TASK TIME ‚Üí EMPLOYEE CONVERSION\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîÑ BLOCK 5: TASK TIME ‚Üí EMPLOYEE CONVERSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: task_forecasts, employee_models\n",
    "print(\"üì• INPUT: task_forecasts (Prophet predictions), employee_models (Regression models)\")\n",
    "\n",
    "employee_predictions = {}\n",
    "conversion_results = []\n",
    "\n",
    "print(\"üîÑ CONVERTING TASK TIME FORECASTS TO EMPLOYEE PREDICTIONS:\")\n",
    "\n",
    "for section, forecast_data in task_forecasts.items():\n",
    "    if section not in employee_models:\n",
    "        print(f\"   ‚ö†Ô∏è  {section}: No regression model available\")\n",
    "        continue\n",
    "\n",
    "    model_info = employee_models[section]\n",
    "    dates = forecast_data['dates']\n",
    "    predicted_task_time = forecast_data['predictions']\n",
    "\n",
    "    # Method 1: Regression prediction\n",
    "    predicted_employees_reg = model_info['regression_model'].predict(predicted_task_time.reshape(-1, 1))\n",
    "    \n",
    "    # Method 2: Efficiency-based prediction\n",
    "    predicted_employees_eff = predicted_task_time / model_info['avg_task_per_employee']\n",
    "\n",
    "    # Combine predictions based on regression R¬≤\n",
    "    r2_val = model_info['training_r2']\n",
    "    weight_reg = REGRESSION_WEIGHT_HIGH if r2_val > REGRESSION_WEIGHT_THRESHOLD else REGRESSION_WEIGHT_LOW\n",
    "\n",
    "    final_predictions = weight_reg * predicted_employees_reg + (1 - weight_reg) * predicted_employees_eff\n",
    "    final_predictions = np.round(final_predictions).astype(int)\n",
    "    \n",
    "    # Apply constraints\n",
    "    final_predictions = np.clip(\n",
    "        final_predictions,\n",
    "        max(1, model_info['min_employees']),\n",
    "        int(model_info['max_employees'] * 1.2)  # Allow 20% above historical max\n",
    "    )\n",
    "\n",
    "    employee_predictions[section] = {\n",
    "        'dates': dates,\n",
    "        'predictions': final_predictions\n",
    "    }\n",
    "    \n",
    "    conversion_results.append({\n",
    "        'section_id': section,\n",
    "        'forecast_days': len(dates),\n",
    "        'avg_predicted_employees': final_predictions.mean(),\n",
    "        'min_predicted': final_predictions.min(),\n",
    "        'max_predicted': final_predictions.max(),\n",
    "        'regression_weight': weight_reg,\n",
    "        'model_r2': r2_val\n",
    "    })\n",
    "\n",
    "    print(f\"   {section}: {len(dates)} days, Avg employees: {final_predictions.mean():.1f} (Weight: {weight_reg:.1f}, R¬≤: {r2_val:.3f})\")\n",
    "\n",
    "# Create conversion results DataFrame\n",
    "conversion_results_df = pd.DataFrame(conversion_results)\n",
    "\n",
    "# Output: Employee predictions\n",
    "print(f\"\\nüì§ OUTPUT:\")\n",
    "print(f\"   - employee_predictions: Dictionary with {len(employee_predictions)} section predictions\")\n",
    "print(\"   - conversion_results_df: Conversion statistics by section\")\n",
    "\n",
    "print(f\"\\nüîç CONVERSION SUMMARY:\")\n",
    "print(conversion_results_df.round(3))\n",
    "\n",
    "# ===============================\n",
    "# üìä BLOCK 6: PREDICTIONS ASSEMBLY\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä BLOCK 6: PREDICTIONS ASSEMBLY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: test_data, employee_predictions\n",
    "print(\"üì• INPUT: test_data (2024 data), employee_predictions (converted predictions)\")\n",
    "\n",
    "# Create complete predictions DataFrame\n",
    "predictions_df = test_data.copy()\n",
    "predictions_df['predicted_employee_count'] = 0\n",
    "\n",
    "# Map predictions to DataFrame\n",
    "for section, pred_data in employee_predictions.items():\n",
    "    for date, pred in zip(pred_data['dates'], pred_data['predictions']):\n",
    "        mask = (predictions_df['section_id'] == section) & (predictions_df['date'] == date)\n",
    "        predictions_df.loc[mask, 'predicted_employee_count'] = pred\n",
    "\n",
    "# Select relevant columns\n",
    "predictions_df = predictions_df[['date', 'section_id', 'employees_on_duty', \n",
    "                                'total_task_time_minutes', 'predicted_employee_count', 'is_working_day']]\n",
    "\n",
    "print(\"üìä PREDICTIONS ASSEMBLY COMPLETE:\")\n",
    "print(f\"   Total predictions: {len(predictions_df):,} records\")\n",
    "print(f\"   Working day predictions: {len(predictions_df[predictions_df['is_working_day'] == 1]):,} records\")\n",
    "print(f\"   Sections with predictions: {predictions_df[predictions_df['predicted_employee_count'] > 0]['section_id'].nunique()}\")\n",
    "\n",
    "# Output: Complete predictions\n",
    "print(f\"\\nüì§ OUTPUT:\")\n",
    "print(\"   - predictions_df: Complete 2024 predictions with actual values\")\n",
    "\n",
    "print(f\"\\nüîç PREDICTIONS SAMPLE:\")\n",
    "print(predictions_df[predictions_df['is_working_day'] == 1].head(10))\n",
    "\n",
    "# ===============================\n",
    "# üéØ BLOCK 7: MODEL EVALUATION\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ BLOCK 7: MODEL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: predictions_df\n",
    "print(\"üì• INPUT: predictions_df (complete predictions with actuals)\")\n",
    "\n",
    "working_predictions = predictions_df[predictions_df['is_working_day'] == 1].copy()\n",
    "\n",
    "# Overall performance metrics\n",
    "mae_overall = mean_absolute_error(working_predictions['employees_on_duty'], working_predictions['predicted_employee_count'])\n",
    "rmse_overall = np.sqrt(mean_squared_error(working_predictions['employees_on_duty'], working_predictions['predicted_employee_count']))\n",
    "r2_overall = r2_score(working_predictions['employees_on_duty'], working_predictions['predicted_employee_count'])\n",
    "\n",
    "print(f\"üéØ OVERALL PERFORMANCE:\")\n",
    "print(f\"   MAE: {mae_overall:.2f} employees\")\n",
    "print(f\"   RMSE: {rmse_overall:.2f} employees\")\n",
    "print(f\"   R¬≤: {r2_overall:.3f}\")\n",
    "print(f\"   Records evaluated: {len(working_predictions):,}\")\n",
    "\n",
    "# Section-wise evaluation\n",
    "print(f\"\\nüìä SECTION-WISE PERFORMANCE:\")\n",
    "section_evaluation = []\n",
    "\n",
    "for section in working_predictions['section_id'].unique():\n",
    "    section_data = working_predictions[working_predictions['section_id'] == section]\n",
    "    if len(section_data) > 0:\n",
    "        mae_section = mean_absolute_error(section_data['employees_on_duty'], section_data['predicted_employee_count'])\n",
    "        rmse_section = np.sqrt(mean_squared_error(section_data['employees_on_duty'], section_data['predicted_employee_count']))\n",
    "        r2_section = r2_score(section_data['employees_on_duty'], section_data['predicted_employee_count'])\n",
    "\n",
    "        # Calculate efficiency\n",
    "        valid_section = section_data[section_data['employees_on_duty'] > 0].copy()\n",
    "        avg_task_per_emp = (valid_section['total_task_time_minutes'] / valid_section['employees_on_duty']).mean()\n",
    "\n",
    "        section_evaluation.append({\n",
    "            'Section': section,\n",
    "            'MAE': mae_section,\n",
    "            'RMSE': rmse_section,\n",
    "            'R¬≤': r2_section,\n",
    "            'Avg_Task_Per_Employee': avg_task_per_emp,\n",
    "            'Working_Days': len(section_data),\n",
    "            'Actual_Avg': section_data['employees_on_duty'].mean(),\n",
    "            'Predicted_Avg': section_data['predicted_employee_count'].mean()\n",
    "        })\n",
    "\n",
    "        print(f\"   {section}:\")\n",
    "        print(f\"      MAE: {mae_section:.2f}, RMSE: {rmse_section:.2f}, R¬≤: {r2_section:.3f}\")\n",
    "        print(f\"      Avg task/employee: {avg_task_per_emp:.1f} minutes\")\n",
    "        print(f\"      Actual avg: {section_data['employees_on_duty'].mean():.1f}, Predicted avg: {section_data['predicted_employee_count'].mean():.1f}\")\n",
    "\n",
    "# Create evaluation results DataFrame\n",
    "section_evaluation_df = pd.DataFrame(section_evaluation)\n",
    "\n",
    "# Output: Evaluation metrics\n",
    "print(f\"\\nüì§ OUTPUT:\")\n",
    "print(\"   - working_predictions: Working day predictions with actuals\")\n",
    "print(\"   - section_evaluation_df: Detailed evaluation metrics by section\")\n",
    "\n",
    "print(f\"\\nüîç EVALUATION SUMMARY:\")\n",
    "print(section_evaluation_df.round(3))\n",
    "\n",
    "# ===============================\n",
    "# üìà BLOCK 8: VISUALIZATIONS\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà BLOCK 8: VISUALIZATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: working_predictions, section_evaluation_df\n",
    "print(\"üì• INPUT: working_predictions, section_evaluation_df\")\n",
    "\n",
    "print(\"üìä CREATING COMPREHENSIVE VISUALIZATIONS...\")\n",
    "\n",
    "# Create main visualization grid\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# 1. Overall prediction accuracy\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.scatter(working_predictions['employees_on_duty'], working_predictions['predicted_employee_count'], alpha=0.6, s=20)\n",
    "plt.plot([0, working_predictions['employees_on_duty'].max()], [0, working_predictions['employees_on_duty'].max()], 'r--', alpha=0.8)\n",
    "plt.xlabel('Actual Employees')\n",
    "plt.ylabel('Predicted Employees')\n",
    "plt.title(f'Overall Prediction Accuracy\\nR¬≤ = {r2_overall:.3f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. MAE by section\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.bar(section_evaluation_df['Section'], section_evaluation_df['MAE'])\n",
    "plt.xlabel('Section')\n",
    "plt.ylabel('MAE (employees)')\n",
    "plt.title('Mean Absolute Error by Section')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. R¬≤ by section\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.bar(section_evaluation_df['Section'], section_evaluation_df['R¬≤'])\n",
    "plt.xlabel('Section')\n",
    "plt.ylabel('R¬≤ Score')\n",
    "plt.title('R¬≤ Score by Section')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Task time per employee\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.bar(section_evaluation_df['Section'], section_evaluation_df['Avg_Task_Per_Employee'], color='skyblue')\n",
    "plt.xlabel('Section')\n",
    "plt.ylabel('Minutes per Employee')\n",
    "plt.title('Average Task Time per Employee')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Actual vs Predicted averages\n",
    "plt.subplot(3, 3, 5)\n",
    "x = np.arange(len(section_evaluation_df))\n",
    "width = 0.35\n",
    "plt.bar(x - width/2, section_evaluation_df['Actual_Avg'], width, label='Actual', alpha=0.8)\n",
    "plt.bar(x + width/2, section_evaluation_df['Predicted_Avg'], width, label='Predicted', alpha=0.8)\n",
    "plt.xlabel('Section')\n",
    "plt.ylabel('Average Employees')\n",
    "plt.title('Actual vs Predicted Average Employees')\n",
    "plt.xticks(x, section_evaluation_df['Section'], rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6-9. Section-wise scatter plots\n",
    "sections = working_predictions['section_id'].unique()[:4]\n",
    "for i, section in enumerate(sections, 6):\n",
    "    plt.subplot(3, 3, i)\n",
    "    section_data = working_predictions[working_predictions['section_id'] == section]\n",
    "    plt.scatter(section_data['employees_on_duty'], section_data['predicted_employee_count'], alpha=0.6)\n",
    "    plt.plot([0, section_data['employees_on_duty'].max()], [0, section_data['employees_on_duty'].max()], 'r--', alpha=0.8)\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(f'{section} Predictions')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_validation_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Monthly trends comparison\n",
    "print(\"üìä CREATING MONTHLY TRENDS VISUALIZATION...\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "working_predictions['year_month'] = working_predictions['date'].dt.to_period('M')\n",
    "monthly_comparison = working_predictions.groupby(['year_month', 'section_id']).agg({\n",
    "    'employees_on_duty': 'mean',\n",
    "    'predicted_employee_count': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "sections = monthly_comparison['section_id'].unique()\n",
    "for i, section in enumerate(sections):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    section_monthly = monthly_comparison[monthly_comparison['section_id'] == section]\n",
    "    plt.plot(section_monthly['year_month'].astype(str), section_monthly['employees_on_duty'], 'o-', label='Actual', linewidth=2)\n",
    "    plt.plot(section_monthly['year_month'].astype(str), section_monthly['predicted_employee_count'], 's-', label='Predicted', linewidth=2)\n",
    "    plt.title(f'{section} - Monthly Average')\n",
    "    plt.xlabel('Month (2024)')\n",
    "    plt.ylabel('Avg Employees')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('monthly_trends_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Output: Visualization files\n",
    "print(f\"\\nüì§ OUTPUT:\")\n",
    "print(\"   - model_validation_results.png: Main validation visualizations\")\n",
    "print(\"   - monthly_trends_comparison.png: Monthly trend analysis\")\n",
    "print(\"   - monthly_comparison: DataFrame with monthly aggregated data\")\n",
    "\n",
    "# ===============================\n",
    "# üíæ BLOCK 9: SAVE RESULTS\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üíæ BLOCK 9: SAVE RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: All generated DataFrames\n",
    "print(\"üì• INPUT: All analysis and prediction DataFrames\")\n",
    "\n",
    "# Save all important DataFrames\n",
    "predictions_df.to_csv('2024_validation_predictions.csv', index=False)\n",
    "section_evaluation_df.to_csv('validation_performance_by_section.csv', index=False)\n",
    "correlation_df.to_csv('training_correlations.csv', index=False)\n",
    "training_stats_df.to_csv('training_statistics.csv', index=False)\n",
    "regression_results_df.to_csv('regression_model_results.csv', index=False)\n",
    "prophet_results_df.to_csv('prophet_forecast_results.csv', index=False)\n",
    "conversion_results_df.to_csv('task_to_employee_conversion.csv', index=False)\n",
    "monthly_comparison.to_csv('monthly_comparison_2024.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ VALIDATION COMPLETE!\")\n",
    "print(f\"\\nüìÅ FILES SAVED:\")\n",
    "print(f\"   - 2024_validation_predictions.csv: Complete predictions vs actuals\")\n",
    "print(f\"   - validation_performance_by_section.csv: Section-wise evaluation metrics\")\n",
    "print(f\"   - training_correlations.csv: Employee-task time correlations\")\n",
    "print(f\"   - training_statistics.csv: Training data statistics\")\n",
    "print(f\"   - regression_model_results.csv: Regression model performance\")\n",
    "print(f\"   - prophet_forecast_results.csv: Prophet forecasting results\")\n",
    "print(f\"   - task_to_employee_conversion.csv: Task time to employee conversion metrics\")\n",
    "print(f\"   - monthly_comparison_2024.csv: Monthly trends comparison\")\n",
    "\n",
    "print(\"\\nüìä FINAL VALIDATION SUMMARY:\")\n",
    "print(section_evaluation_df.round(3))\n",
    "\n",
    "# Model performance assessment\n",
    "if mae_overall < 1.0:\n",
    "    print(f\"\\n‚úÖ MODEL PERFORMANCE EXCELLENT! (MAE: {mae_overall:.3f} < 1.0)\")\n",
    "    print(\"   Ready for 2025 forecasting deployment.\")\n",
    "elif mae_overall < 1.5:\n",
    "    print(f\"\\n‚úÖ MODEL PERFORMANCE GOOD! (MAE: {mae_overall:.3f} < 1.5)\")\n",
    "    print(\"   Suitable for production use.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  MODEL PERFORMANCE NEEDS IMPROVEMENT (MAE: {mae_overall:.3f})\")\n",
    "    print(\"   Consider hyperparameter tuning before 2025 forecasting.\")\n",
    "\n",
    "print(\"\\nüéâ PIPELINE EXECUTION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
