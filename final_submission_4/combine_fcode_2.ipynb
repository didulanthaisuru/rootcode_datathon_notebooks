{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdd6dda",
   "metadata": {},
   "source": [
    "# Section 1: Train Models and Export as Pickle\n",
    "This section loads the staff dataset, performs feature engineering, trains all models, and exports them as a single pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 📊 EMPLOYEE PREDICTION MODEL - 2025 FORECASTING\n",
    "# Complete Pipeline: Data Processing → Task Time Forecasting → Employee Count Prediction\n",
    "# Training: 2021-2024 | Prediction Target: 2025\n",
    "# ===============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 EMPLOYEE PREDICTION MODEL - 2025 FORECASTING PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===============================\n",
    "# 📂 BLOCK 1: DATA LOADING & PREPROCESSING\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📂 BLOCK 1: DATA LOADING & PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Input: Raw staffing data CSV\n",
    "print(\"📥 INPUT: staffing_train.csv\")\n",
    "\n",
    "# Load staffing data\n",
    "staff_df = pd.read_csv(\"staffing_train.csv\")\n",
    "staff_df['date'] = pd.to_datetime(staff_df['date'])\n",
    "\n",
    "print(f\"📊 LOADED DATA OVERVIEW:\")\n",
    "print(f\"   Staffing records: {len(staff_df):,}\")\n",
    "print(f\"   Date range: {staff_df['date'].min()} to {staff_df['date'].max()}\")\n",
    "print(f\"   Sections: {staff_df['section_id'].nunique()}\")\n",
    "\n",
    "# Generate all dates from 2021-01-01 to 2025-12-31\n",
    "print(\"\\n🔄 GENERATING COMPLETE DATE RANGE (2021-2025)...\")\n",
    "all_dates = pd.date_range(start=\"2021-01-01\", end=\"2025-12-31\")\n",
    "\n",
    "# Filter weekends (Saturday=5, Sunday=6)\n",
    "weekend_dates = all_dates[all_dates.weekday.isin([5, 6])]\n",
    "weekend_df = pd.DataFrame({'date': weekend_dates})\n",
    "weekend_df['weekday'] = weekend_df['date'].dt.day_name()\n",
    "\n",
    "# Sri Lanka holidays for 2021-2025\n",
    "print(\"📅 ADDING HOLIDAY DATA...\")\n",
    "web_holiday_data = [\n",
    "    # 2021 Holidays\n",
    "    ('2021-01-14', 'Tamil Thai Pongal Day'),\n",
    "    ('2021-01-28', 'Duruthu Full Moon Poya'),\n",
    "    ('2021-02-04', 'National Day'),\n",
    "    ('2021-02-26', 'Navam Full Moon Poya'),\n",
    "    ('2021-03-11', 'Mahasivarathri Day'),\n",
    "    ('2021-03-28', 'Madin Full Moon Poya'),\n",
    "    ('2021-04-02', 'Good Friday'),\n",
    "    ('2021-04-12', 'Sinhala and Tamil New Year Holiday'),\n",
    "    ('2021-04-13', 'Sinhala and Tamil New Year Eve'),\n",
    "    ('2021-04-14', 'Sinhala and Tamil New Year'),\n",
    "    ('2021-04-26', 'Bak Full Moon Poya'),\n",
    "    ('2021-05-01', 'Labour Day'),\n",
    "    ('2021-05-14', 'Id-Ul-Fitr (Ramazan Festival Day)'),\n",
    "    ('2021-05-24', 'Special Public Holiday'),\n",
    "    ('2021-05-25', 'Special Public Holiday'),\n",
    "    ('2021-05-26', 'Vesak Full Moon Poya'),\n",
    "    ('2021-05-27', 'Vesak Full Moon Poya Holiday'),\n",
    "    ('2021-06-24', 'Poson Full Moon Poya'),\n",
    "    ('2021-07-21', 'Idul Adha'),\n",
    "    ('2021-07-23', 'Esala Full Moon Poya'),\n",
    "    ('2021-08-22', 'Nikini Full Moon Poya'),\n",
    "    ('2021-09-20', 'Binara Full Moon Poya'),\n",
    "    ('2021-10-19', 'Milad-Un-Nabi'),\n",
    "    ('2021-10-20', 'Vap Full Moon Poya'),\n",
    "    ('2021-11-04', 'Deepavali Festival Day'),\n",
    "    ('2021-11-18', 'Ill Full Moon Poya'),\n",
    "    ('2021-12-18', 'Unduvap Full Moon Poya'),\n",
    "    ('2021-12-25', 'Christmas Day'),\n",
    "    # 2022 Holidays\n",
    "    ('2022-01-14', 'Tamil Thai Pongal Day'),\n",
    "    ('2022-01-17', 'Duruthu Full Moon Poya'),\n",
    "    ('2022-02-04', 'National Day'),\n",
    "    ('2022-02-16', 'Navam Full Moon Poya'),\n",
    "    ('2022-03-01', 'Mahasivarathri Day'),\n",
    "    ('2022-03-17', 'Madin Full Moon Poya'),\n",
    "    ('2022-04-11', 'Special Public Holiday'),\n",
    "    ('2022-04-12', 'Special Public Holiday'),\n",
    "    ('2022-04-13', 'Sinhala and Tamil New Year Eve'),\n",
    "    ('2022-04-14', 'Sinhala and Tamil New Year'),\n",
    "    ('2022-04-15', 'Good Friday'),\n",
    "    ('2022-04-16', 'Bak Full Moon Poya'),\n",
    "    ('2022-05-01', 'Labour Day'),\n",
    "    ('2022-05-02', 'Labour Day (in lieu)'),\n",
    "    ('2022-05-03', 'Id-Ul-Fitr'),\n",
    "    ('2022-05-15', 'Vesak Full Moon Poya'),\n",
    "    ('2022-05-16', 'Vesak Full Moon Poya Holiday'),\n",
    "    ('2022-06-13', 'Special Public Holiday'),\n",
    "    ('2022-06-14', 'Poson Full Moon Poya'),\n",
    "    ('2022-06-17', 'Sri Lanka Friday Holiday'),\n",
    "    ('2022-06-24', 'Sri Lanka Friday Holiday'),\n",
    "    ('2022-07-01', 'Sri Lanka Friday Holiday'),\n",
    "    ('2022-07-08', 'Sri Lanka Friday Holiday'),\n",
    "    ('2022-07-10', 'Idul Adha'),\n",
    "    ('2022-07-13', 'Esala Full Moon Poya'),\n",
    "    ('2022-07-15', 'Sri Lanka Friday Holiday'),\n",
    "    ('2022-07-22', 'Sri Lanka Friday Holiday'),\n",
    "    ('2022-07-29', 'Sri Lanka Friday Holiday'),\n",
    "    ('2022-08-11', 'Nikini Full Moon Poya'),\n",
    "    ('2022-09-10', 'Binara Full Moon Poya'),\n",
    "    ('2022-09-19', 'Special Public Holiday'),\n",
    "    ('2022-10-09', 'Vap Full Moon Poya'),\n",
    "    ('2022-10-09', 'Milad-Un-Nabi'),\n",
    "    ('2022-10-10', 'Milad-Un-Nabi (in lieu)'),\n",
    "    ('2022-10-24', 'Deepavali Festival Day'),\n",
    "    ('2022-11-07', 'Ill Full Moon Poya'),\n",
    "    ('2022-12-07', 'Unduvap Full Moon Poya'),\n",
    "    ('2022-12-25', 'Christmas Day'),\n",
    "    ('2022-12-26', 'Special Public Holiday (in lieu)'),\n",
    "    # 2023 Holidays\n",
    "    ('2023-01-06', 'Duruthu Full Moon Poya'),\n",
    "    ('2023-01-15', 'Tamil Thai Pongal Day'),\n",
    "    ('2023-02-04', 'National Day'),\n",
    "    ('2023-02-05', 'Navam Full Moon Poya'),\n",
    "    ('2023-02-18', 'Mahasivarathri Day'),\n",
    "    ('2023-03-06', 'Madin Full Moon Poya'),\n",
    "    ('2023-04-05', 'Bak Full Moon Poya'),\n",
    "    ('2023-04-07', 'Good Friday'),\n",
    "    ('2023-04-13', 'Sinhala and Tamil New Year Eve'),\n",
    "    ('2023-04-14', 'Sinhala and Tamil New Year'),\n",
    "    ('2023-04-22', 'Id-Ul-Fitr'),\n",
    "    ('2023-05-01', 'Labour Day'),\n",
    "    ('2023-05-05', 'Vesak Full Moon Poya'),\n",
    "    ('2023-05-06', 'Vesak Full Moon Poya Holiday'),\n",
    "    ('2023-06-03', 'Poson Full Moon Poya'),\n",
    "    ('2023-06-29', 'Idul Adha'),\n",
    "    ('2023-07-03', 'Esala Full Moon Poya'),\n",
    "    ('2023-08-01', 'Nikini Full Moon Poya'),\n",
    "    ('2023-08-30', 'Adhi Nikini Full Moon Poya'),\n",
    "    ('2023-09-28', 'Milad-Un-Nabi'),\n",
    "    ('2023-09-29', 'Binara Full Moon Poya'),\n",
    "    ('2023-10-28', 'Vap Full Moon Poya'),\n",
    "    ('2023-11-12', 'Deepavali Festival Day'),\n",
    "    ('2023-11-26', 'Ill Full Moon Poya'),\n",
    "    ('2023-12-25', 'Christmas Day'),\n",
    "    ('2023-12-26', 'Unduvap Full Moon Poya'),\n",
    "    # 2024 Holidays\n",
    "    ('2024-01-15', 'Tamil Thai Pongal Day'),\n",
    "    ('2024-01-25', 'Duruthu Full Moon Poya'),\n",
    "    ('2024-02-04', 'National Day'),\n",
    "    ('2024-02-23', 'Navam Full Moon Poya'),\n",
    "    ('2024-03-08', 'Mahasivarathri Day'),\n",
    "    ('2024-03-24', 'Madin Full Moon Poya'),\n",
    "    ('2024-03-29', 'Good Friday'),\n",
    "    ('2024-04-11', 'Id-Ul-Fitr'),\n",
    "    ('2024-04-12', 'Sinhala and Tamil New Year Eve'),\n",
    "    ('2024-04-13', 'Sinhala and Tamil New Year'),\n",
    "    ('2024-04-15', 'Sinhala and Tamil New Year (in lieu)'),\n",
    "    ('2024-04-23', 'Bak Full Moon Poya'),\n",
    "    ('2024-05-01', 'Labour Day'),\n",
    "    ('2024-05-23', 'Vesak Full Moon Poya'),\n",
    "    ('2024-05-24', 'Vesak Full Moon Poya Holiday'),\n",
    "    ('2024-06-17', 'Idul Adha'),\n",
    "    ('2024-06-21', 'Poson Full Moon Poya'),\n",
    "    ('2024-07-20', 'Esala Full Moon Poya'),\n",
    "    ('2024-08-19', 'Nikini Full Moon Poya'),\n",
    "    ('2024-09-16', 'Milad-Un-Nabi'),\n",
    "    ('2024-09-17', 'Binara Full Moon Poya'),\n",
    "    ('2024-09-23', 'Public Holiday'),\n",
    "    ('2024-10-17', 'Vap Full Moon Poya'),\n",
    "    ('2024-10-31', 'Deepavali Festival Day'),\n",
    "    ('2024-11-15', 'Ill Full Moon Poya'),\n",
    "    ('2024-12-14', 'Unduvap Full Moon Poya'),\n",
    "    ('2024-12-25', 'Christmas Day'),\n",
    "    # 2025 Holidays\n",
    "    ('2025-01-13', 'Duruthu Full Moon Poya'),\n",
    "    ('2025-01-14', 'Tamil Thai Pongal Day'),\n",
    "    ('2025-02-04', 'National Day'),\n",
    "    ('2025-02-12', 'Navam Full Moon Poya'),\n",
    "    ('2025-02-26', 'Mahasivarathri Day'),\n",
    "    ('2025-03-13', 'Madin Full Moon Poya'),\n",
    "    ('2025-03-31', 'Id-Ul-Fitr'),\n",
    "    ('2025-04-12', 'Bak Full Moon Poya'),\n",
    "    ('2025-04-13', 'Sinhala and Tamil New Year Eve'),\n",
    "    ('2025-04-14', 'Sinhala and Tamil New Year'),\n",
    "    ('2025-04-15', 'Special Bank Holiday'),\n",
    "    ('2025-04-18', 'Good Friday'),\n",
    "    ('2025-05-01', 'Labour Day'),\n",
    "    ('2025-05-12', 'Vesak Full Moon Poya'),\n",
    "    ('2025-05-13', 'Vesak Full Moon Poya Holiday'),\n",
    "    ('2025-06-07', 'Idul Adha'),\n",
    "    ('2025-06-10', 'Poson Full Moon Poya'),\n",
    "    ('2025-07-10', 'Esala Full Moon Poya'),\n",
    "    ('2025-08-08', 'Nikini Full Moon Poya'),\n",
    "    ('2025-09-05', 'Milad-Un-Nabi'),\n",
    "    ('2025-09-07', 'Binara Full Moon Poya'),\n",
    "    ('2025-10-06', 'Vap Full Moon Poya'),\n",
    "    ('2025-10-20', 'Deepavali Festival Day'),\n",
    "    ('2025-11-05', 'Ill Full Moon Poya'),\n",
    "    ('2025-12-04', 'Unduvap Full Moon Poya'),\n",
    "    ('2025-12-25', 'Christmas Day'),\n",
    "]\n",
    "web_holiday_df = pd.DataFrame(web_holiday_data, columns=['date', 'holiday_name'])\n",
    "web_holiday_df['date'] = pd.to_datetime(web_holiday_df['date'])\n",
    "\n",
    "# Exclude specific dates\n",
    "exclude_dates = [\n",
    "    '2023-09-29', '2022-05-02', '2023-06-29', '2022-06-24', '2022-07-08', '2024-09-23',\n",
    "    '2022-06-13', '2022-09-19', '2023-08-30', '2022-07-15', '2022-07-01', '2023-03-06',\n",
    "    '2021-05-25', '2022-07-22', '2022-07-29', '2021-05-24', '2022-06-17'\n",
    "]\n",
    "exclude_dates_dt = pd.to_datetime(exclude_dates)\n",
    "filtered_holiday = web_holiday_df[~web_holiday_df['date'].isin(exclude_dates_dt)].reset_index(drop=True)\n",
    "\n",
    "# Create final DataFrame by combining staff, weekend, and filtered_holiday\n",
    "print(\"\\n🔄 CREATING COMBINED DATASET...\")\n",
    "sections = staff_df['section_id'].unique()\n",
    "final_rows = []\n",
    "for date in all_dates:\n",
    "    for section in sections:\n",
    "        staff_row = staff_df[(staff_df['date'] == date) & (staff_df['section_id'] == section)]\n",
    "        employees_on_duty = staff_row['employees_on_duty'].values[0] if not staff_row.empty else 0\n",
    "        total_task_time_minutes = staff_row['total_task_time_minutes'].values[0] if not staff_row.empty else 0\n",
    "        weekend_row = weekend_df[weekend_df['date'] == date]\n",
    "        weekday = weekend_row['weekday'].values[0] if not weekend_row.empty else 0\n",
    "        holiday_row = filtered_holiday[filtered_holiday['date'] == date]\n",
    "        holiday_name = holiday_row['holiday_name'].values[0] if not holiday_row.empty else 0\n",
    "        final_rows.append({\n",
    "            'date': date,\n",
    "            'section_id': section,\n",
    "            'employees_on_duty': employees_on_duty,\n",
    "            'total_task_time_minutes': total_task_time_minutes,\n",
    "            'weekday': weekday,\n",
    "            'holiday_name': holiday_name\n",
    "        })\n",
    "final_df = pd.DataFrame(final_rows)\n",
    "final_df['date'] = pd.to_datetime(final_df['date'])\n",
    "\n",
    "# Convert 'holiday_name' and 'weekday' to binary columns\n",
    "final_df['is_holiday'] = final_df['holiday_name'].apply(lambda x: 1 if x != 0 else 0)\n",
    "final_df['is_weekend'] = final_df['weekday'].apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "# Drop the original 'holiday_name' and 'weekday' columns\n",
    "df = final_df.drop(['holiday_name', 'weekday'], axis=1)\n",
    "print(f\"✅ COMPLETE DATASET CREATED: {len(df):,} records\")\n",
    "\n",
    "# Feature engineering\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "df['is_working_day'] = ((df['is_holiday'] == 0) & (df['is_weekend'] == 0)).astype(int)\n",
    "\n",
    "# Train-Test Split: Now using 2021-2024 for training, 2025 for prediction\n",
    "train_data = df[df['year'] <= 2024].copy()\n",
    "prediction_data = df[df['year'] == 2025].copy()\n",
    "\n",
    "print(\"📊 FINAL DATA OVERVIEW:\")\n",
    "print(f\"   Total records: {len(df):,}\")\n",
    "print(f\"   Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"   Sections: {df['section_id'].nunique()}\")\n",
    "print(f\"   Training data: {len(train_data):,} records (2021-2024)\")\n",
    "print(f\"   Prediction target: {len(prediction_data):,} records (2025)\")\n",
    "\n",
    "# ===============================\n",
    "# 🔧 CONFIGURATION PARAMETERS\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔧 CONFIGURATION PARAMETERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Section-specific Prophet hyperparameters (tuned with Optuna)\n",
    "PROPHET_PARAMS = {\n",
    "    'SEC-001': {\n",
    "        'changepoint_prior_scale': 0.029254338019126417,\n",
    "        'seasonality_prior_scale': 0.01030759392216948,\n",
    "        'holidays_prior_scale': 4.864715869874991,\n",
    "        'fourier_order_monthly': 10,\n",
    "        'fourier_order_quarterly': 5\n",
    "    },\n",
    "    'SEC-002': {\n",
    "        'changepoint_prior_scale': 0.22762138954332634,\n",
    "        'seasonality_prior_scale': 0.014000919327379695,\n",
    "        'holidays_prior_scale': 0.18467713067993052,\n",
    "        'fourier_order_monthly': 4,\n",
    "        'fourier_order_quarterly': 3\n",
    "    },\n",
    "    'SEC-003': {\n",
    "        'changepoint_prior_scale': 0.10098846366877628,\n",
    "        'seasonality_prior_scale': 1.543871763639119,\n",
    "        'holidays_prior_scale': 1.21711608065993,\n",
    "        'fourier_order_monthly': 6,\n",
    "        'fourier_order_quarterly': 3\n",
    "    },\n",
    "    'SEC-004': {\n",
    "        'changepoint_prior_scale': 0.005151892778933222,\n",
    "        'seasonality_prior_scale': 0.9459006529861674,\n",
    "        'holidays_prior_scale': 0.10358719372494084,\n",
    "        'fourier_order_monthly': 4,\n",
    "        'fourier_order_quarterly': 3\n",
    "    },\n",
    "    'SEC-005': {\n",
    "        'changepoint_prior_scale': 0.004362487854811211,\n",
    "        'seasonality_prior_scale': 0.013350235089538814,\n",
    "        'holidays_prior_scale': 15.35123292088448,\n",
    "        'fourier_order_monthly': 4,\n",
    "        'fourier_order_quarterly': 9\n",
    "    },\n",
    "    'SEC-006': {\n",
    "        'changepoint_prior_scale': 0.0015881037419492121,\n",
    "        'seasonality_prior_scale': 0.03300723715996255,\n",
    "        'holidays_prior_scale': 14.07408779964586,\n",
    "        'fourier_order_monthly': 5,\n",
    "        'fourier_order_quarterly': 4\n",
    "    }\n",
    "}\n",
    "\n",
    "# Default parameters (fallback for any missing sections)\n",
    "DEFAULT_PROPHET_PARAMS = {\n",
    "    'changepoint_prior_scale': 0.05,\n",
    "    'seasonality_prior_scale': 8.0,\n",
    "    'holidays_prior_scale': 10.0,\n",
    "    'fourier_order_monthly': 5,\n",
    "    'fourier_order_quarterly': 3\n",
    "}\n",
    "\n",
    "# Optimized HuberRegressor Parameters (from hyperparameter tuning)\n",
    "OPTIMIZED_HUBER_PARAMS = {\n",
    "    'SEC-001': {'epsilon': 2.5, 'alpha': 2.3819256646753313e-06, 'max_iter': 450, 'fit_intercept': True},\n",
    "    'SEC-002': {'epsilon': 1.3, 'alpha': 0.043570676782234655, 'max_iter': 600, 'fit_intercept': True},\n",
    "    'SEC-003': {'epsilon': 1.3, 'alpha': 5.002881133425486e-06, 'max_iter': 1550, 'fit_intercept': True},\n",
    "    'SEC-004': {'epsilon': 1.0, 'alpha': 0.002086668812396698, 'max_iter': 300, 'fit_intercept': True},\n",
    "    'SEC-005': {'epsilon': 1.4, 'alpha': 0.0001800366193826709, 'max_iter': 1350, 'fit_intercept': True},\n",
    "    'SEC-006': {'epsilon': 2.5, 'alpha': 2.3819256646753313e-06, 'max_iter': 450, 'fit_intercept': True}\n",
    "}\n",
    "\n",
    "# Default HuberRegressor parameters (fallback for new sections)\n",
    "DEFAULT_HUBER_PARAMS = {\n",
    "    'epsilon': 1.35,\n",
    "    'alpha': 0.0001,\n",
    "    'max_iter': 1000,\n",
    "    'fit_intercept': True\n",
    "}\n",
    "\n",
    "# Model parameters\n",
    "REGRESSION_WEIGHT_THRESHOLD = 0.9  # R² threshold for regression weight\n",
    "REGRESSION_WEIGHT_HIGH = 0.8       # Weight when R² > threshold\n",
    "REGRESSION_WEIGHT_LOW = 0.6        # Weight when R² <= threshold\n",
    "\n",
    "def get_huber_params(section_id):\n",
    "    \"\"\"Get optimized HuberRegressor parameters for a section\"\"\"\n",
    "    return OPTIMIZED_HUBER_PARAMS.get(section_id, DEFAULT_HUBER_PARAMS)\n",
    "\n",
    "print(\"📋 CONFIGURATION:\")\n",
    "print(\"   Section-specific Prophet Parameters:\")\n",
    "for section, params in PROPHET_PARAMS.items():\n",
    "    print(f\"   {section}: CPS={params['changepoint_prior_scale']}, SPS={params['seasonality_prior_scale']}, \"\n",
    "          f\"HPS={params['holidays_prior_scale']}, Monthly={params['fourier_order_monthly']}, Quarterly={params['fourier_order_quarterly']}\")\n",
    "print(f\"   Default fallback parameters available for new sections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "#  BLOCK 2: TRAINING DATA ANALYSIS (2021-2024)\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📈 BLOCK 2: TRAINING DATA ANALYSIS (2021-2024)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "working_train = train_data[train_data['is_working_day'] == 1]\n",
    "\n",
    "print(\"📊 CORRELATION ANALYSIS (Employee vs Task Time):\")\n",
    "correlations = {}\n",
    "correlation_results = []\n",
    "\n",
    "for section in working_train['section_id'].unique():\n",
    "    section_data = working_train[working_train['section_id'] == section]\n",
    "    if len(section_data) > 20:\n",
    "        corr = section_data['employees_on_duty'].corr(section_data['total_task_time_minutes'])\n",
    "        correlations[section] = corr\n",
    "        correlation_results.append({\n",
    "            'section_id': section,\n",
    "            'correlation': corr,\n",
    "            'data_points': len(section_data)\n",
    "        })\n",
    "        print(f\"   {section}: {corr:.3f} ({len(section_data)} data points)\")\n",
    "\n",
    "# Create correlation DataFrame\n",
    "correlation_df = pd.DataFrame(correlation_results)\n",
    "\n",
    "print(f\"\\n📈 TRAINING STATISTICS BY SECTION (2021-2024):\")\n",
    "stats = working_train.groupby('section_id').agg({\n",
    "    'employees_on_duty': ['count', 'mean', 'std', 'min', 'max'],\n",
    "    'total_task_time_minutes': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "training_stats = []\n",
    "for section in stats.index:\n",
    "    emp_stats = stats.loc[section, 'employees_on_duty']\n",
    "    task_stats = stats.loc[section, 'total_task_time_minutes']\n",
    "    \n",
    "    training_stats.append({\n",
    "        'section_id': section,\n",
    "        'working_days': emp_stats['count'],\n",
    "        'emp_mean': emp_stats['mean'],\n",
    "        'emp_std': emp_stats['std'],\n",
    "        'emp_min': emp_stats['min'],\n",
    "        'emp_max': emp_stats['max'],\n",
    "        'task_mean': task_stats['mean'],\n",
    "        'task_std': task_stats['std']\n",
    "    })\n",
    "    \n",
    "    print(f\"   {section}:\")\n",
    "    print(f\"      Working days: {emp_stats['count']:.0f}\")\n",
    "    print(f\"      Employees: {emp_stats['mean']:.1f} ± {emp_stats['std']:.1f} (range: {emp_stats['min']:.0f}-{emp_stats['max']:.0f})\")\n",
    "    print(f\"      Task time: {task_stats['mean']:.0f} ± {task_stats['std']:.0f} minutes\")\n",
    "\n",
    "# Create training statistics DataFrame\n",
    "training_stats_df = pd.DataFrame(training_stats)\n",
    "\n",
    "# ===============================\n",
    "# 🤖 BLOCK 3: EMPLOYEE REGRESSION MODELS (Updated with 2021-2024)\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🤖 BLOCK 3: EMPLOYEE REGRESSION MODELS (2021-2024 Training)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "employee_models = {}\n",
    "regression_results = []\n",
    "\n",
    "print(\"🔨 BUILDING REGRESSION MODELS (Task Time → Employee Count):\")\n",
    "\n",
    "for section in working_train['section_id'].unique():\n",
    "    section_data = working_train[working_train['section_id'] == section]\n",
    "\n",
    "    if len(section_data) > 30:\n",
    "        # Prepare regression data\n",
    "        X = section_data[['total_task_time_minutes']].values\n",
    "        y = section_data['employees_on_duty'].values\n",
    "\n",
    "        # Get optimized parameters for this section\n",
    "        huber_params = get_huber_params(section)\n",
    "\n",
    "        # Build optimized model\n",
    "        model = HuberRegressor(**huber_params)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # Calculate efficiency metrics\n",
    "        valid_data = section_data[section_data['employees_on_duty'] > 0].copy()\n",
    "        valid_data['task_per_emp'] = valid_data['total_task_time_minutes'] / valid_data['employees_on_duty']\n",
    "\n",
    "        # Store model information\n",
    "        r2_score_val = model.score(X, y)\n",
    "        \n",
    "        employee_models[section] = {\n",
    "            'regression_model': model,\n",
    "            'avg_task_per_employee': valid_data['task_per_emp'].median(),\n",
    "            'min_employees': section_data['employees_on_duty'].min(),\n",
    "            'max_employees': section_data['employees_on_duty'].max(),\n",
    "            'training_r2': r2_score_val\n",
    "        }\n",
    "\n",
    "        regression_results.append({\n",
    "            'section_id': section,\n",
    "            'r2_score': r2_score_val,\n",
    "            'avg_efficiency': valid_data['task_per_emp'].median(),\n",
    "            'min_employees': section_data['employees_on_duty'].min(),\n",
    "            'max_employees': section_data['employees_on_duty'].max(),\n",
    "            'training_samples': len(section_data)\n",
    "        })\n",
    "\n",
    "        print(f\"   {section}: R² = {r2_score_val:.3f}, Avg efficiency = {valid_data['task_per_emp'].median():.1f} min/emp\")\n",
    "\n",
    "# Create regression results DataFrame\n",
    "regression_results_df = pd.DataFrame(regression_results)\n",
    "\n",
    "print(f\"\\n🔍 REGRESSION SUMMARY:\")\n",
    "print(regression_results_df.round(2))\n",
    "\n",
    "# ===============================\n",
    "# 🔮 BLOCK 4: PROPHET TASK TIME FORECASTING FOR 2025\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔮 BLOCK 4: PROPHET TASK TIME FORECASTING FOR 2025\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "task_forecasts_2025 = {}\n",
    "task_time_models_2025 = {}\n",
    "prophet_results_2025 = []\n",
    "\n",
    "print(\"📊 FORECASTING 2025 TASK TIME WITH PROPHET (including regressors)...\")\n",
    "\n",
    "for section in working_train['section_id'].unique():\n",
    "    print(f\"   Forecasting {section} for 2025...\")\n",
    "    section_data = working_train[working_train['section_id'] == section].copy()\n",
    "\n",
    "    if len(section_data) < 50:\n",
    "        print(f\"      ⚠️  Insufficient training data ({len(section_data)} records)\")\n",
    "        continue\n",
    "\n",
    "    # Prepare Prophet DataFrame\n",
    "    prophet_df = section_data[['date', 'total_task_time_minutes', 'is_weekend', 'is_holiday']].copy()\n",
    "    prophet_df.columns = ['ds', 'y', 'is_weekend', 'is_holiday']\n",
    "    prophet_df = prophet_df.sort_values('ds')\n",
    "\n",
    "    # Section-specific parameters or fallback\n",
    "    section_params = PROPHET_PARAMS.get(section, DEFAULT_PROPHET_PARAMS)\n",
    "    \n",
    "    # Build Prophet model\n",
    "    model = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=False,\n",
    "        changepoint_prior_scale=section_params['changepoint_prior_scale'],\n",
    "        seasonality_prior_scale=section_params['seasonality_prior_scale'],\n",
    "        holidays_prior_scale=section_params['holidays_prior_scale']\n",
    "    )\n",
    "\n",
    "    # Add custom seasonalities\n",
    "    model.add_seasonality(name='monthly', period=30.5, fourier_order=section_params['fourier_order_monthly'])\n",
    "    model.add_seasonality(name='quarterly', period=91.25, fourier_order=section_params['fourier_order_quarterly'])\n",
    "    \n",
    "    # Add regressors\n",
    "    model.add_regressor('is_weekend', prior_scale=0.5)\n",
    "    model.add_regressor('is_holiday', prior_scale=1.0)\n",
    "\n",
    "    # Fit model with regressors\n",
    "    model.fit(prophet_df[['ds', 'y', 'is_weekend', 'is_holiday']])\n",
    "\n",
    "    # Prepare 2025 forecast dates with regressors\n",
    "    prediction_working_2025 = prediction_data[(prediction_data['section_id'] == section) & (prediction_data['is_working_day'] == 1)].copy()\n",
    "    if len(prediction_working_2025) > 0:\n",
    "        future_df_2025 = prediction_working_2025[['date', 'is_weekend', 'is_holiday']].copy()\n",
    "        future_df_2025.columns = ['ds', 'is_weekend', 'is_holiday']\n",
    "        forecast_2025 = model.predict(future_df_2025)\n",
    "        forecast_2025['yhat'] = forecast_2025['yhat'].clip(lower=0)\n",
    "\n",
    "        task_forecasts_2025[section] = {\n",
    "            'dates': future_df_2025['ds'].values,\n",
    "            'predictions': forecast_2025['yhat'].values,\n",
    "            'lower_bound': forecast_2025['yhat_lower'].values,\n",
    "            'upper_bound': forecast_2025['yhat_upper'].values\n",
    "        }\n",
    "        task_time_models_2025[section] = model\n",
    "\n",
    "        # Training MAE on 2021-2024 data\n",
    "        train_forecast = model.predict(prophet_df[['ds', 'is_weekend', 'is_holiday']])\n",
    "        train_mae = mean_absolute_error(prophet_df['y'], train_forecast['yhat'])\n",
    "\n",
    "        prophet_results_2025.append({\n",
    "            'section_id': section,\n",
    "            'training_samples_2021_2024': len(prophet_df),\n",
    "            'forecast_days_2025': len(future_df_2025),\n",
    "            'train_mae_2021_2024': train_mae,\n",
    "            'avg_predicted_task_time_2025': forecast_2025['yhat'].mean(),\n",
    "            'min_predicted_2025': forecast_2025['yhat'].min(),\n",
    "            'max_predicted_2025': forecast_2025['yhat'].max(),\n",
    "            'changepoint_prior_scale': section_params['changepoint_prior_scale'],\n",
    "            'seasonality_prior_scale': section_params['seasonality_prior_scale'],\n",
    "            'holidays_prior_scale': section_params['holidays_prior_scale'],\n",
    "            'fourier_monthly': section_params['fourier_order_monthly'],\n",
    "            'fourier_quarterly': section_params['fourier_order_quarterly']\n",
    "        })\n",
    "        \n",
    "        print(f\"      → Forecasted {len(future_df_2025)} working days in 2025\")\n",
    "        print(f\"         Avg: {forecast_2025['yhat'].mean():.1f} min, Range: {forecast_2025['yhat'].min():.1f}-{forecast_2025['yhat'].max():.1f}\")\n",
    "        print(f\"         Training MAE (2021-2024): {train_mae:.1f}\")\n",
    "\n",
    "# Create Prophet results DataFrame\n",
    "prophet_results_2025_df = pd.DataFrame(prophet_results_2025)\n",
    "\n",
    "print(f\"\\n PROPHET 2025 FORECAST SUMMARY:\")\n",
    "print(prophet_results_2025_df.round(2))\n",
    "\n",
    "# ===============================\n",
    "# 🔄 BLOCK 5: 2025 TASK TIME → EMPLOYEE CONVERSION\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔄 BLOCK 5: 2025 TASK TIME → EMPLOYEE CONVERSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "employee_predictions_2025 = {}\n",
    "conversion_results_2025 = []\n",
    "\n",
    "print(\"🔄 CONVERTING 2025 TASK TIME FORECASTS TO EMPLOYEE PREDICTIONS:\")\n",
    "\n",
    "for section, forecast_data in task_forecasts_2025.items():\n",
    "    if section not in employee_models:\n",
    "        print(f\"   ⚠️  {section}: No regression model available\")\n",
    "        continue\n",
    "\n",
    "    model_info = employee_models[section]\n",
    "    dates = forecast_data['dates']\n",
    "    predicted_task_time = forecast_data['predictions']\n",
    "    lower_bound = forecast_data['lower_bound']\n",
    "    upper_bound = forecast_data['upper_bound']\n",
    "\n",
    "    # Method 1: Regression prediction\n",
    "    predicted_employees_reg = model_info['regression_model'].predict(predicted_task_time.reshape(-1, 1))\n",
    "    \n",
    "    # Method 2: Efficiency-based prediction\n",
    "    predicted_employees_eff = predicted_task_time / model_info['avg_task_per_employee']\n",
    "\n",
    "    # Combine predictions based on regression R²\n",
    "    r2_val = model_info['training_r2']\n",
    "    weight_reg = REGRESSION_WEIGHT_HIGH if r2_val > REGRESSION_WEIGHT_THRESHOLD else REGRESSION_WEIGHT_LOW\n",
    "\n",
    "    final_predictions = weight_reg * predicted_employees_reg + (1 - weight_reg) * predicted_employees_eff\n",
    "    final_predictions = np.round(final_predictions).astype(int)\n",
    "    \n",
    "    # Calculate confidence bounds for employees\n",
    "    employees_lower = np.round(lower_bound / model_info['avg_task_per_employee']).astype(int)\n",
    "    employees_upper = np.round(upper_bound / model_info['avg_task_per_employee']).astype(int)\n",
    "    \n",
    "    # Apply constraints\n",
    "    final_predictions = np.clip(\n",
    "        final_predictions,\n",
    "        max(1, model_info['min_employees']),\n",
    "        int(model_info['max_employees'] * 1.3)  # Allow 30% above historical max for 2025\n",
    "    )\n",
    "    \n",
    "    employees_lower = np.clip(employees_lower, max(1, model_info['min_employees']), final_predictions)\n",
    "    employees_upper = np.clip(employees_upper, final_predictions, int(model_info['max_employees'] * 1.5))\n",
    "\n",
    "    employee_predictions_2025[section] = {\n",
    "        'dates': dates,\n",
    "        'predictions': final_predictions,\n",
    "        'lower_bound': employees_lower,\n",
    "        'upper_bound': employees_upper\n",
    "    }\n",
    "    \n",
    "    conversion_results_2025.append({\n",
    "        'section_id': section,\n",
    "        'forecast_days_2025': len(dates),\n",
    "        'avg_predicted_employees_2025': final_predictions.mean(),\n",
    "        'min_predicted_2025': final_predictions.min(),\n",
    "        'max_predicted_2025': final_predictions.max(),\n",
    "        'regression_weight': weight_reg,\n",
    "        'model_r2': r2_val,\n",
    "        'avg_confidence_range': (employees_upper - employees_lower).mean()\n",
    "    })\n",
    "\n",
    "    print(f\"   {section}: {len(dates)} working days in 2025\")\n",
    "    print(f\"      Avg employees: {final_predictions.mean():.1f} (range: {final_predictions.min()}-{final_predictions.max()})\")\n",
    "    print(f\"      Model weight: {weight_reg:.1f}, R²: {r2_val:.3f}\")\n",
    "\n",
    "# Create conversion results DataFrame\n",
    "conversion_results_2025_df = pd.DataFrame(conversion_results_2025)\n",
    "\n",
    "print(f\"\\n 2025 CONVERSION SUMMARY:\")\n",
    "print(conversion_results_2025_df.round(3))\n",
    "\n",
    "# ===============================\n",
    "# 📊 BLOCK 6: 2025 COMPLETE PREDICTIONS ASSEMBLY\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📊 BLOCK 6: 2025 COMPLETE PREDICTIONS ASSEMBLY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create complete 2025 predictions DataFrame\n",
    "complete_final_full_2025_dataset = prediction_data.copy()\n",
    "complete_final_full_2025_dataset['predicted_employee_count'] = 0\n",
    "complete_final_full_2025_dataset['predicted_task_time_minutes'] = 0.0\n",
    "complete_final_full_2025_dataset['employee_lower_bound'] = 0\n",
    "complete_final_full_2025_dataset['employee_upper_bound'] = 0\n",
    "complete_final_full_2025_dataset['task_time_lower_bound'] = 0.0\n",
    "complete_final_full_2025_dataset['task_time_upper_bound'] = 0.0\n",
    "\n",
    "# Map employee predictions to DataFrame\n",
    "for section, pred_data in employee_predictions_2025.items():\n",
    "    for i, date in enumerate(pred_data['dates']):\n",
    "        mask = (complete_final_full_2025_dataset['section_id'] == section) & (complete_final_full_2025_dataset['date'] == date)\n",
    "        complete_final_full_2025_dataset.loc[mask, 'predicted_employee_count'] = pred_data['predictions'][i]\n",
    "        complete_final_full_2025_dataset.loc[mask, 'employee_lower_bound'] = pred_data['lower_bound'][i]\n",
    "        complete_final_full_2025_dataset.loc[mask, 'employee_upper_bound'] = pred_data['upper_bound'][i]\n",
    "\n",
    "# Map task time predictions to DataFrame\n",
    "for section, forecast_data in task_forecasts_2025.items():\n",
    "    for i, date in enumerate(forecast_data['dates']):\n",
    "        mask = (complete_final_full_2025_dataset['section_id'] == section) & (complete_final_full_2025_dataset['date'] == date)\n",
    "        complete_final_full_2025_dataset.loc[mask, 'predicted_task_time_minutes'] = forecast_data['predictions'][i]\n",
    "        complete_final_full_2025_dataset.loc[mask, 'task_time_lower_bound'] = forecast_data['lower_bound'][i]\n",
    "        complete_final_full_2025_dataset.loc[mask, 'task_time_upper_bound'] = forecast_data['upper_bound'][i]\n",
    "\n",
    "print(\"📊 2025 PREDICTIONS ASSEMBLY COMPLETE:\")\n",
    "print(f\"   Total 2025 records: {len(complete_final_full_2025_dataset):,}\")\n",
    "print(f\"   Working day predictions: {len(complete_final_full_2025_dataset[complete_final_full_2025_dataset['is_working_day'] == 1]):,}\")\n",
    "print(f\"   Sections with predictions: {complete_final_full_2025_dataset[complete_final_full_2025_dataset['predicted_employee_count'] > 0]['section_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\n🔍 2025 PREDICTIONS SAMPLE:\")\n",
    "working_sample = complete_final_full_2025_dataset[complete_final_full_2025_dataset['is_working_day'] == 1].head(15)\n",
    "print(working_sample[['date', 'section_id', 'predicted_employee_count', 'predicted_task_time_minutes', \n",
    "                      'employee_lower_bound', 'employee_upper_bound']].to_string())\n",
    "\n",
    "# ===============================\n",
    "# 📈 BLOCK 7: 2025 PREDICTION ANALYSIS & INSIGHTS\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📈 BLOCK 7: 2025 PREDICTION ANALYSIS & INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "working_2025_predictions = complete_final_full_2025_dataset[complete_final_full_2025_dataset['is_working_day'] == 1].copy()\n",
    "\n",
    "print(f\"📊 2025 WORKFORCE PLANNING INSIGHTS:\")\n",
    "print(f\"   Total working days in 2025: {len(working_2025_predictions):,}\")\n",
    "\n",
    "# Section-wise 2025 analysis\n",
    "section_analysis_2025 = []\n",
    "print(f\"\\n📋 SECTION-WISE 2025 PREDICTIONS:\")\n",
    "\n",
    "for section in working_2025_predictions['section_id'].unique():\n",
    "    section_data = working_2025_predictions[working_2025_predictions['section_id'] == section]\n",
    "    if len(section_data) > 0:\n",
    "        \n",
    "        # Monthly patterns\n",
    "        section_data['month'] = section_data['date'].dt.month\n",
    "        monthly_avg = section_data.groupby('month')['predicted_employee_count'].mean()\n",
    "        \n",
    "        # Quarterly patterns  \n",
    "        section_data['quarter'] = section_data['date'].dt.quarter\n",
    "        quarterly_avg = section_data.groupby('quarter')['predicted_employee_count'].mean()\n",
    "        \n",
    "        # Peak and low periods\n",
    "        peak_month = monthly_avg.idxmax()\n",
    "        low_month = monthly_avg.idxmin()\n",
    "        \n",
    "        section_analysis_2025.append({\n",
    "            'Section': section,\n",
    "            'Working_Days_2025': len(section_data),\n",
    "            'Avg_Employees_2025': section_data['predicted_employee_count'].mean(),\n",
    "            'Min_Employees_2025': section_data['predicted_employee_count'].min(),\n",
    "            'Max_Employees_2025': section_data['predicted_employee_count'].max(),\n",
    "            'Avg_Task_Time_2025': section_data['predicted_task_time_minutes'].mean(),\n",
    "            'Peak_Month': peak_month,\n",
    "            'Peak_Month_Avg': monthly_avg[peak_month],\n",
    "            'Low_Month': low_month,\n",
    "            'Low_Month_Avg': monthly_avg[low_month],\n",
    "            'Q1_Avg': quarterly_avg.get(1, 0),\n",
    "            'Q2_Avg': quarterly_avg.get(2, 0),\n",
    "            'Q3_Avg': quarterly_avg.get(3, 0),\n",
    "            'Q4_Avg': quarterly_avg.get(4, 0),\n",
    "            'Total_Employee_Days_2025': section_data['predicted_employee_count'].sum()\n",
    "        })\n",
    "\n",
    "        print(f\"   {section}:\")\n",
    "        print(f\"      Working days: {len(section_data)}\")\n",
    "        print(f\"      Avg employees: {section_data['predicted_employee_count'].mean():.1f} (range: {section_data['predicted_employee_count'].min()}-{section_data['predicted_employee_count'].max()})\")\n",
    "        print(f\"      Peak: Month {peak_month} ({monthly_avg[peak_month]:.1f} avg), Low: Month {low_month} ({monthly_avg[low_month]:.1f} avg)\")\n",
    "        print(f\"      Quarterly averages: Q1={quarterly_avg.get(1, 0):.1f}, Q2={quarterly_avg.get(2, 0):.1f}, Q3={quarterly_avg.get(3, 0):.1f}, Q4={quarterly_avg.get(4, 0):.1f}\")\n",
    "\n",
    "# Create 2025 analysis DataFrame\n",
    "section_analysis_2025_df = pd.DataFrame(section_analysis_2025)\n",
    "\n",
    "# Overall 2025 insights\n",
    "total_employee_days_2025 = working_2025_predictions['predicted_employee_count'].sum()\n",
    "avg_daily_workforce_2025 = working_2025_predictions['predicted_employee_count'].mean()\n",
    "total_task_time_2025 = working_2025_predictions['predicted_task_time_minutes'].sum()\n",
    "\n",
    "print(f\"\\n🎯 2025 OVERALL WORKFORCE INSIGHTS:\")\n",
    "print(f\"   Total employee-days needed: {total_employee_days_2025:,}\")\n",
    "print(f\"   Average daily workforce: {avg_daily_workforce_2025:.1f} employees\")\n",
    "print(f\"   Total predicted task time: {total_task_time_2025:,.0f} minutes ({total_task_time_2025/60:,.0f} hours)\")\n",
    "print(f\"   Average daily task time: {total_task_time_2025/len(working_2025_predictions):,.0f} minutes per day\")\n",
    "\n",
    "# Monthly workforce planning\n",
    "print(f\"\\n📅 2025 MONTHLY WORKFORCE PLANNING:\")\n",
    "monthly_workforce = working_2025_predictions.groupby(working_2025_predictions['date'].dt.month).agg({\n",
    "    'predicted_employee_count': ['sum', 'mean', 'max'],\n",
    "    'predicted_task_time_minutes': 'sum'\n",
    "}).round(1)\n",
    "\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "for month in range(1, 13):\n",
    "    if month in monthly_workforce.index:\n",
    "        emp_sum = monthly_workforce.loc[month, ('predicted_employee_count', 'sum')]\n",
    "        emp_avg = monthly_workforce.loc[month, ('predicted_employee_count', 'mean')]\n",
    "        emp_max = monthly_workforce.loc[month, ('predicted_employee_count', 'max')]\n",
    "        task_sum = monthly_workforce.loc[month, ('predicted_task_time_minutes', 'sum')]\n",
    "        print(f\"   {month_names[month-1]} 2025: {emp_sum:,.0f} employee-days, {emp_avg:.1f} avg daily, {emp_max:.0f} peak daily, {task_sum/60:,.0f} total hours\")\n",
    "\n",
    "# ===============================\n",
    "# 📈 BLOCK 8: 2025 VISUALIZATIONS\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📈 BLOCK 8: 2025 VISUALIZATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"📊 CREATING COMPREHENSIVE 2025 VISUALIZATIONS...\")\n",
    "\n",
    "# Create main 2025 visualization grid\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "plt.suptitle('2025 Employee Workforce Predictions - Comprehensive Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Monthly workforce trends\n",
    "plt.subplot(3, 3, 1)\n",
    "monthly_totals = working_2025_predictions.groupby(working_2025_predictions['date'].dt.month)['predicted_employee_count'].sum()\n",
    "plt.bar(range(1, 13), [monthly_totals.get(i, 0) for i in range(1, 13)], color='skyblue', alpha=0.8)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Employee-Days')\n",
    "plt.title('2025 Monthly Workforce Requirements')\n",
    "plt.xticks(range(1, 13), [month_names[i-1] for i in range(1, 13)], rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Section-wise average employees\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.bar(section_analysis_2025_df['Section'], section_analysis_2025_df['Avg_Employees_2025'], color='lightcoral', alpha=0.8)\n",
    "plt.xlabel('Section')\n",
    "plt.ylabel('Average Employees')\n",
    "plt.title('2025 Average Employees by Section')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Peak vs Low month comparison\n",
    "plt.subplot(3, 3, 3)\n",
    "x = np.arange(len(section_analysis_2025_df))\n",
    "width = 0.35\n",
    "plt.bar(x - width/2, section_analysis_2025_df['Peak_Month_Avg'], width, label='Peak Month', alpha=0.8, color='red')\n",
    "plt.bar(x + width/2, section_analysis_2025_df['Low_Month_Avg'], width, label='Low Month', alpha=0.8, color='green')\n",
    "plt.xlabel('Section')\n",
    "plt.ylabel('Average Employees')\n",
    "plt.title('2025 Peak vs Low Month Staffing')\n",
    "plt.xticks(x, section_analysis_2025_df['Section'], rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Quarterly workforce distribution\n",
    "plt.subplot(3, 3, 4)\n",
    "quarterly_data = section_analysis_2025_df[['Q1_Avg', 'Q2_Avg', 'Q3_Avg', 'Q4_Avg']].mean()\n",
    "plt.pie(quarterly_data, labels=['Q1', 'Q2', 'Q3', 'Q4'], autopct='%1.1f%%', startangle=90)\n",
    "plt.title('2025 Quarterly Workforce Distribution')\n",
    "\n",
    "# 5. Task time vs Employee count correlation\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.scatter(working_2025_predictions['predicted_task_time_minutes'], \n",
    "           working_2025_predictions['predicted_employee_count'], alpha=0.6, s=20)\n",
    "plt.xlabel('Predicted Task Time (minutes)')\n",
    "plt.ylabel('Predicted Employee Count')\n",
    "plt.title('2025 Task Time vs Employee Relationship')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Working days distribution by section\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.bar(section_analysis_2025_df['Section'], section_analysis_2025_df['Working_Days_2025'], color='orange', alpha=0.8)\n",
    "plt.xlabel('Section')\n",
    "plt.ylabel('Working Days')\n",
    "plt.title('2025 Working Days by Section')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 7-9. Section-specific time series for top 3 sections by workforce\n",
    "top_sections = section_analysis_2025_df.nlargest(3, 'Total_Employee_Days_2025')['Section'].tolist()\n",
    "for i, section in enumerate(top_sections, 7):\n",
    "    plt.subplot(3, 3, i)\n",
    "    section_data = working_2025_predictions[working_2025_predictions['section_id'] == section]\n",
    "    # Resample to weekly averages for cleaner visualization\n",
    "    section_weekly = section_data.set_index('date').resample('W')['predicted_employee_count'].mean()\n",
    "    plt.plot(section_weekly.index, section_weekly.values, linewidth=2, marker='o', markersize=3)\n",
    "    plt.xlabel('2025 Date')\n",
    "    plt.ylabel('Avg Weekly Employees')\n",
    "    plt.title(f'{section} - 2025 Weekly Trends')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('2025_workforce_predictions_comprehensive.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Create confidence intervals visualization\n",
    "print(\"📊 CREATING 2025 CONFIDENCE INTERVALS VISUALIZATION...\")\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('2025 Employee Predictions with Confidence Intervals by Section', fontsize=14, fontweight='bold')\n",
    "\n",
    "sections_with_predictions = working_2025_predictions[working_2025_predictions['predicted_employee_count'] > 0]['section_id'].unique()\n",
    "for i, section in enumerate(sections_with_predictions[:6]):  # Top 6 sections\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    section_data = working_2025_predictions[working_2025_predictions['section_id'] == section].copy()\n",
    "    section_data = section_data.sort_values('date')\n",
    "    \n",
    "    # Monthly aggregation for cleaner visualization\n",
    "    monthly_data = section_data.set_index('date').resample('M').agg({\n",
    "        'predicted_employee_count': 'mean',\n",
    "        'employee_lower_bound': 'mean',\n",
    "        'employee_upper_bound': 'mean'\n",
    "    })\n",
    "    \n",
    "    ax.plot(monthly_data.index, monthly_data['predicted_employee_count'], 'b-', linewidth=2, label='Predicted')\n",
    "    ax.fill_between(monthly_data.index, monthly_data['employee_lower_bound'], \n",
    "                   monthly_data['employee_upper_bound'], alpha=0.3, color='blue', label='Confidence Range')\n",
    "    ax.set_title(f'{section} - 2025 Monthly Predictions')\n",
    "    ax.set_xlabel('2025 Month')\n",
    "    ax.set_ylabel('Employees')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('2025_confidence_intervals_by_section.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ===============================\n",
    "# 💾 BLOCK 9: SAVE 2025 RESULTS\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"💾 BLOCK 9: SAVE 2025 RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save all important 2025 DataFrames\n",
    "complete_final_full_2025_dataset.to_csv('complete_final_full_2025_dataset.csv', index=False)\n",
    "section_analysis_2025_df.to_csv('2025_workforce_analysis_by_section.csv', index=False)\n",
    "working_2025_predictions.to_csv('2025_working_days_predictions.csv', index=False)\n",
    "correlation_df.to_csv('2021_2024_training_correlations.csv', index=False)\n",
    "training_stats_df.to_csv('2021_2024_training_statistics.csv', index=False)\n",
    "regression_results_df.to_csv('2021_2024_regression_model_results.csv', index=False)\n",
    "prophet_results_2025_df.to_csv('2025_prophet_forecast_results.csv', index=False)\n",
    "conversion_results_2025_df.to_csv('2025_task_to_employee_conversion.csv', index=False)\n",
    "\n",
    "# Save monthly workforce planning data\n",
    "monthly_workforce_df = pd.DataFrame({\n",
    "    'Month': range(1, 13),\n",
    "    'Month_Name': month_names,\n",
    "    'Total_Employee_Days': [monthly_workforce.loc[i, ('predicted_employee_count', 'sum')] if i in monthly_workforce.index else 0 for i in range(1, 13)],\n",
    "    'Avg_Daily_Employees': [monthly_workforce.loc[i, ('predicted_employee_count', 'mean')] if i in monthly_workforce.index else 0 for i in range(1, 13)],\n",
    "    'Peak_Daily_Employees': [monthly_workforce.loc[i, ('predicted_employee_count', 'max')] if i in monthly_workforce.index else 0 for i in range(1, 13)],\n",
    "    'Total_Task_Hours': [monthly_workforce.loc[i, ('predicted_task_time_minutes', 'sum')]/60 if i in monthly_workforce.index else 0 for i in range(1, 13)]\n",
    "})\n",
    "monthly_workforce_df.to_csv('2025_monthly_workforce_planning.csv', index=False)\n",
    "\n",
    "print(\"✅ 2025 FORECASTING COMPLETE!\")\n",
    "print(f\"\\n📁 FILES SAVED:\")\n",
    "print(f\"   - complete_final_full_2025_dataset.csv: ⭐ MAIN OUTPUT - Complete 2025 predictions with confidence intervals\")\n",
    "print(f\"   - 2025_workforce_analysis_by_section.csv: Section-wise 2025 workforce analysis\")\n",
    "print(f\"   - 2025_working_days_predictions.csv: Working days only 2025 predictions\")\n",
    "print(f\"   - 2025_monthly_workforce_planning.csv: Monthly workforce planning summary\")\n",
    "print(f\"   - 2021_2024_training_correlations.csv: Updated training correlations\")\n",
    "print(f\"   - 2021_2024_training_statistics.csv: Updated training statistics\")\n",
    "print(f\"   - 2021_2024_regression_model_results.csv: Updated regression model performance\")\n",
    "print(f\"   - 2025_prophet_forecast_results.csv: 2025 Prophet forecasting results\")\n",
    "print(f\"   - 2025_task_to_employee_conversion.csv: 2025 conversion metrics\")\n",
    "\n",
    "print(\"\\n📊 FINAL 2025 WORKFORCE SUMMARY:\")\n",
    "print(section_analysis_2025_df.round(2))\n",
    "\n",
    "print(f\"\\n🎯 2025 KEY METRICS:\")\n",
    "print(f\"   📅 Total working days: {len(working_2025_predictions):,}\")\n",
    "print(f\"   👥 Total employee-days needed: {total_employee_days_2025:,}\")\n",
    "print(f\"   📈 Average daily workforce: {avg_daily_workforce_2025:.1f} employees\")\n",
    "print(f\"   ⏱️  Total predicted task time: {total_task_time_2025/60:,.0f} hours\")\n",
    "print(f\"   🏢 Sections covered: {len(section_analysis_2025_df)}\")\n",
    "\n",
    "# Workforce planning recommendations\n",
    "print(f\"\\n💡 2025 WORKFORCE PLANNING RECOMMENDATIONS:\")\n",
    "peak_month = monthly_workforce[('predicted_employee_count', 'sum')].idxmax()\n",
    "low_month = monthly_workforce[('predicted_employee_count', 'sum')].idxmin()\n",
    "print(f\"   📈 Peak staffing month: {month_names[peak_month-1]} ({monthly_workforce.loc[peak_month, ('predicted_employee_count', 'sum')]:,.0f} employee-days)\")\n",
    "print(f\"   📉 Lowest staffing month: {month_names[low_month-1]} ({monthly_workforce.loc[low_month, ('predicted_employee_count', 'sum')]:,.0f} employee-days)\")\n",
    "\n",
    "# Identify sections needing most attention\n",
    "high_variance_sections = section_analysis_2025_df[section_analysis_2025_df['Max_Employees_2025'] - section_analysis_2025_df['Min_Employees_2025'] > 3]\n",
    "if len(high_variance_sections) > 0:\n",
    "    print(f\"   ⚠️  Sections with high staffing variability:\")\n",
    "    for _, section in high_variance_sections.iterrows():\n",
    "        print(f\"      {section['Section']}: {section['Min_Employees_2025']}-{section['Max_Employees_2025']} employees (range: {section['Max_Employees_2025']-section['Min_Employees_2025']})\")\n",
    "\n",
    "print(f\"\\n🎉 2025 EMPLOYEE FORECASTING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"📋 Main output file: 'complete_final_full_2025_dataset.csv'\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 🥒 MODEL EXPORT TO PICKLE FILES\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🥒 EXPORTING MODELS TO PICKLE FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Create a single dictionary with all model components\n",
    "all_models = {\n",
    "    'employee_models': employee_models,\n",
    "    'task_time_models_2025': task_time_models_2025,\n",
    "    'PROPHET_PARAMS': PROPHET_PARAMS,\n",
    "    'DEFAULT_PROPHET_PARAMS': DEFAULT_PROPHET_PARAMS,\n",
    "    'OPTIMIZED_HUBER_PARAMS': OPTIMIZED_HUBER_PARAMS,\n",
    "    'DEFAULT_HUBER_PARAMS': DEFAULT_HUBER_PARAMS,\n",
    "    'REGRESSION_WEIGHT_THRESHOLD': REGRESSION_WEIGHT_THRESHOLD,\n",
    "    'REGRESSION_WEIGHT_HIGH': REGRESSION_WEIGHT_HIGH,\n",
    "    'REGRESSION_WEIGHT_LOW': REGRESSION_WEIGHT_LOW\n",
    "}\n",
    "\n",
    "# Export all models and parameters to a single pickle file\n",
    "with open('predictions_full.pkl', 'wb') as f:\n",
    "    pickle.dump(all_models, f)\n",
    "print(\"✅ Exported all models and parameters to predictions_full.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68848f",
   "metadata": {},
   "source": [
    "load_pkl and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc33760",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_evaluation_input=pd.read_csv(\"task2_test_inputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 📤 LOAD PICKLE MODEL FILES FOR PREDICTION\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📤 LOADING MODELS FROM PICKLE FILE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load all models and parameters from the single pickle file\n",
    "try:\n",
    "    with open('predictions_full.pkl', 'rb') as f:\n",
    "        all_models = pickle.load(f)\n",
    "    print(\"✅ Successfully loaded all models and parameters\")\n",
    "    \n",
    "    # Extract individual components from the loaded dictionary\n",
    "    loaded_employee_models = all_models['employee_models']\n",
    "    loaded_task_time_models = all_models['task_time_models_2025']\n",
    "    PROPHET_PARAMS = all_models['PROPHET_PARAMS']\n",
    "    DEFAULT_PROPHET_PARAMS = all_models['DEFAULT_PROPHET_PARAMS']\n",
    "    OPTIMIZED_HUBER_PARAMS = all_models['OPTIMIZED_HUBER_PARAMS']\n",
    "    DEFAULT_HUBER_PARAMS = all_models['DEFAULT_HUBER_PARAMS']\n",
    "    REGRESSION_WEIGHT_THRESHOLD = all_models['REGRESSION_WEIGHT_THRESHOLD']\n",
    "    REGRESSION_WEIGHT_HIGH = all_models['REGRESSION_WEIGHT_HIGH']\n",
    "    REGRESSION_WEIGHT_LOW = all_models['REGRESSION_WEIGHT_LOW']\n",
    "    \n",
    "    print(\"📊 Loaded model components:\")\n",
    "    print(f\"   Employee models for {len(loaded_employee_models)} sections\")\n",
    "    print(f\"   Task time models for {len(loaded_task_time_models)} sections\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Model file not found. Please run the model export cell first.\")\n",
    "    # Use the ones in memory as fallback\n",
    "    loaded_employee_models = employee_models\n",
    "    loaded_task_time_models = task_time_models_2025\n",
    "    print(\"⚠️ Using models from current memory instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 🔍 PREPARE EVALUATION INPUT DATA\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔍 PREPARING EVALUATION INPUT DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display information about the evaluation input\n",
    "print(f\"📊 Evaluation Input Overview:\")\n",
    "print(f\"   Total rows: {len(task_2_evaluation_input):,}\")\n",
    "print(f\"   Columns: {', '.join(task_2_evaluation_input.columns)}\")\n",
    "\n",
    "# Convert date to datetime if needed\n",
    "if 'date' in task_2_evaluation_input.columns and not pd.api.types.is_datetime64_any_dtype(task_2_evaluation_input['date']):\n",
    "    task_2_evaluation_input['date'] = pd.to_datetime(task_2_evaluation_input['date'])\n",
    "    print(\"✅ Converted date column to datetime\")\n",
    "\n",
    "# Add necessary features similar to the training data\n",
    "task_2_evaluation_input['year'] = task_2_evaluation_input['date'].dt.year\n",
    "task_2_evaluation_input['month'] = task_2_evaluation_input['date'].dt.month\n",
    "task_2_evaluation_input['dayofweek'] = task_2_evaluation_input['date'].dt.dayofweek\n",
    "task_2_evaluation_input['quarter'] = task_2_evaluation_input['date'].dt.quarter\n",
    "\n",
    "# Check if we need to add weekend/holiday features\n",
    "if 'is_weekend' not in task_2_evaluation_input.columns:\n",
    "    # Check if the dates are in the weekend (5=Saturday, 6=Sunday)\n",
    "    task_2_evaluation_input['is_weekend'] = task_2_evaluation_input['date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "    print(\"✅ Added weekend flag\")\n",
    "    \n",
    "if 'is_holiday' not in task_2_evaluation_input.columns:\n",
    "    # Add holiday information (reuse the holiday data from before)\n",
    "    filtered_holiday_dict = dict(zip(pd.to_datetime(filtered_holiday['date']), [1] * len(filtered_holiday)))\n",
    "    task_2_evaluation_input['is_holiday'] = task_2_evaluation_input['date'].map(\n",
    "        lambda x: 1 if x in filtered_holiday_dict else 0)\n",
    "    print(\"✅ Added holiday flag\")\n",
    "    \n",
    "if 'is_working_day' not in task_2_evaluation_input.columns:\n",
    "    # Add working day flag (not weekend and not holiday)\n",
    "    task_2_evaluation_input['is_working_day'] = ((task_2_evaluation_input['is_holiday'] == 0) & \n",
    "                                                (task_2_evaluation_input['is_weekend'] == 0)).astype(int)\n",
    "    print(\"✅ Added working day flag\")\n",
    "\n",
    "# Print summary of working vs non-working days\n",
    "working_count = task_2_evaluation_input['is_working_day'].sum()\n",
    "weekend_count = task_2_evaluation_input['is_weekend'].sum()\n",
    "holiday_count = (task_2_evaluation_input['is_holiday'] & ~task_2_evaluation_input['is_weekend']).sum()\n",
    "\n",
    "print(f\"\\n📅 Day Type Summary:\")\n",
    "print(f\"   Working Days: {working_count}\")\n",
    "print(f\"   Weekend Days: {weekend_count}\")\n",
    "print(f\"   Holiday Days (excluding weekends): {holiday_count}\")\n",
    "print(f\"   Total: {len(task_2_evaluation_input)}\")\n",
    "\n",
    "# Show sample of prepared data\n",
    "print(\"\\n📋 Sample of prepared evaluation data:\")\n",
    "print(task_2_evaluation_input.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a842bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 🔮 MAKE PREDICTIONS ON EVALUATION DATA\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔮 MAKING PREDICTIONS ON EVALUATION DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check what columns are available\n",
    "print(f\"Columns in evaluation data: {task_2_evaluation_input.columns.tolist()}\")\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "predictions_df = task_2_evaluation_input[['row_id']].copy()\n",
    "predictions_df['true_required_employees'] = 0\n",
    "\n",
    "# Make predictions for each row\n",
    "print(f\"🔍 Making predictions for {len(task_2_evaluation_input)} rows...\")\n",
    "\n",
    "# First, predict task times for each section\n",
    "section_task_times = {}\n",
    "sections_to_process = task_2_evaluation_input['section_id'].unique()\n",
    "\n",
    "print(\"Step 1: Predicting task times using Prophet models...\")\n",
    "for section in sections_to_process:\n",
    "    if section in loaded_task_time_models:\n",
    "        # Get the Prophet model for this section\n",
    "        prophet_model = loaded_task_time_models[section]\n",
    "        \n",
    "        # Prepare future dataframe for this section\n",
    "        section_dates = task_2_evaluation_input[task_2_evaluation_input['section_id'] == section]\n",
    "        future_df = section_dates[['date', 'is_weekend', 'is_holiday']].copy()\n",
    "        future_df.columns = ['ds', 'is_weekend', 'is_holiday']\n",
    "        \n",
    "        # Make predictions\n",
    "        forecast = prophet_model.predict(future_df)\n",
    "        \n",
    "        # Store predictions in a dictionary keyed by (section, date) for quick lookup\n",
    "        for i, row in forecast.iterrows():\n",
    "            date = row['ds']\n",
    "            predicted_time = max(0, row['yhat'])  # Ensure non-negative\n",
    "            section_task_times[(section, date)] = predicted_time\n",
    "        \n",
    "        print(f\"  - {section}: Predicted task times for {len(future_df)} dates\")\n",
    "    else:\n",
    "        print(f\"  - ⚠️ No Prophet model available for {section}, will use averages\")\n",
    "        \n",
    "        # Use average from training data as fallback\n",
    "        section_data = working_train[working_train['section_id'] == section]\n",
    "        if len(section_data) > 0:\n",
    "            avg_task_time = section_data['total_task_time_minutes'].mean()\n",
    "        else:\n",
    "            avg_task_time = working_train['total_task_time_minutes'].mean()\n",
    "            \n",
    "        # Apply to all dates for this section\n",
    "        section_dates = task_2_evaluation_input[task_2_evaluation_input['section_id'] == section]['date'].unique()\n",
    "        for date in section_dates:\n",
    "            section_task_times[(section, date)] = avg_task_time\n",
    "\n",
    "print(\"\\nStep 2: Converting predicted task times to employee counts...\")\n",
    "for index, row in task_2_evaluation_input.iterrows():\n",
    "    section = row['section_id']\n",
    "    date = row['date']\n",
    "    is_weekend = row['is_weekend']\n",
    "    is_holiday = row['is_holiday']\n",
    "    row_id = row['row_id']\n",
    "    \n",
    "    # Check if it's a weekend or holiday\n",
    "    if is_weekend == 1 or is_holiday == 1:\n",
    "        # For weekends or holidays, set employee count to 0\n",
    "        predictions_df.loc[predictions_df['row_id'] == row_id, 'true_required_employees'] = 0\n",
    "        continue\n",
    "    \n",
    "    # For working days (not weekends or holidays), proceed with prediction\n",
    "    # Get the predicted task time for this section and date\n",
    "    task_time = section_task_times.get((section, date), 0)\n",
    "    \n",
    "    # Check if we have models for this section\n",
    "    if section in loaded_employee_models:\n",
    "        model_info = loaded_employee_models[section]\n",
    "        \n",
    "        # Method 1: Use regression model to predict\n",
    "        predicted_employees_reg = model_info['regression_model'].predict(\n",
    "            np.array([[task_time]])\n",
    "        )[0]\n",
    "        \n",
    "        # Method 2: Use efficiency-based calculation\n",
    "        predicted_employees_eff = task_time / model_info['avg_task_per_employee'] if model_info['avg_task_per_employee'] > 0 else 0\n",
    "        \n",
    "        # Combine predictions based on regression R²\n",
    "        r2_val = model_info['training_r2']\n",
    "        weight_reg = REGRESSION_WEIGHT_HIGH if r2_val > REGRESSION_WEIGHT_THRESHOLD else REGRESSION_WEIGHT_LOW\n",
    "        \n",
    "        final_prediction = weight_reg * predicted_employees_reg + (1 - weight_reg) * predicted_employees_eff\n",
    "        \n",
    "        # For working days, ensure at least 1 employee\n",
    "        final_prediction = max(1, min(int(round(final_prediction)), int(model_info['max_employees'] * 1.3)))\n",
    "        \n",
    "        predictions_df.loc[predictions_df['row_id'] == row_id, 'true_required_employees'] = final_prediction\n",
    "    else:\n",
    "        # Fallback for sections without models - use a simple formula based on average efficiency\n",
    "        avg_efficiency = 60  # Assuming 60 minutes per employee is a reasonable default\n",
    "        predicted_employees = task_time / avg_efficiency if avg_efficiency > 0 else 1\n",
    "        \n",
    "        # For working days, ensure at least 1 employee\n",
    "        final_prediction = max(1, int(round(predicted_employees)))\n",
    "        \n",
    "        predictions_df.loc[predictions_df['row_id'] == row_id, 'true_required_employees'] = final_prediction\n",
    "\n",
    "print(f\"✅ Predictions complete for {len(predictions_df)} rows\")\n",
    "print(\"\\n📊 Predictions Summary:\")\n",
    "print(f\"   Min predicted employees: {predictions_df['true_required_employees'].min()}\")\n",
    "print(f\"   Max predicted employees: {predictions_df['true_required_employees'].max()}\")\n",
    "print(f\"   Mean predicted employees: {predictions_df['true_required_employees'].mean():.2f}\")\n",
    "print(\"\\n📋 Sample predictions:\")\n",
    "print(predictions_df.head(10))\n",
    "\n",
    "# Count records by working day status\n",
    "working_days = len(predictions_df[predictions_df['true_required_employees'] > 0])\n",
    "non_working_days = len(predictions_df[predictions_df['true_required_employees'] == 0])\n",
    "print(f\"\\n📅 Working Days: {working_days} (with employees > 0)\")\n",
    "print(f\"📅 Non-Working Days: {non_working_days} (with employees = 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dac74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 💾 SAVE PREDICTIONS TO CSV FILE\n",
    "# ===============================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"💾 SAVING PREDICTIONS TO CSV FILE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define the output filename\n",
    "output_filename = 'task2_predictions.csv'\n",
    "\n",
    "# Save only the required columns: row_id and true_required_employees\n",
    "predictions_output = predictions_df[['row_id', 'true_required_employees']]\n",
    "predictions_output.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"✅ Successfully saved predictions to {output_filename}\")\n",
    "print(f\"   Total rows: {len(predictions_output):,}\")\n",
    "print(f\"   Columns: {', '.join(predictions_output.columns)}\")\n",
    "\n",
    "# Display the first few rows of the saved file\n",
    "print(\"\\n📋 Preview of saved predictions:\")\n",
    "print(predictions_output.head(10))\n",
    "\n",
    "# Display output statistics by section\n",
    "print(\"\\n📊 Prediction Statistics by Section:\")\n",
    "merged_df = task_2_evaluation_input.merge(predictions_df, on='row_id')\n",
    "section_stats = merged_df.groupby('section_id')['true_required_employees'].agg(['count', 'mean', 'min', 'max'])\n",
    "print(section_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b044186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b623f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7701a3c2",
   "metadata": {},
   "source": [
    "# Section 2: Load Models and Predict for Task 2\n",
    "This section loads the trained models from the pickle file, processes the test input data, performs feature engineering, and generates predictions for `task2_test_inputs.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b31be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171c58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Load Models and Predict for Task 2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import holidays\n",
    "import os\n",
    "\n",
    "# Load trained models from pickle file\n",
    "with open('all_models.pkl', 'rb') as f:\n",
    "    all_models = pickle.load(f)\n",
    "\n",
    "# Load test input data\n",
    "test_df = pd.read_csv('task2_test_inputs.csv')\n",
    "\n",
    "# Feature engineering for test data\n",
    "def add_features(df):\n",
    "    # Convert date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    # Add day of week\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    # Add weekend indicator\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    # Add holiday indicator (Sri Lanka example, change country as needed)\n",
    "    sl_holidays = holidays.CountryHoliday('LK', years=df['date'].dt.year.unique())\n",
    "    df['is_holiday'] = df['date'].isin(sl_holidays).astype(int)\n",
    "    # Add month\n",
    "    df['month'] = df['date'].dt.month\n",
    "    # Add year\n",
    "    df['year'] = df['date'].dt.year\n",
    "    # Add any other features as needed\n",
    "    return df\n",
    "\n",
    "test_df = add_features(test_df)\n",
    "\n",
    "# Make predictions using loaded models (example, adapt to your model structure)\n",
    "# Example: If all_models contains a model per section_id\n",
    "predictions = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    section_id = row['section_id']\n",
    "    model = all_models.get(section_id)\n",
    "    if model:\n",
    "        # Prepare features for prediction (update as per your model requirements)\n",
    "        features = row[['day_of_week', 'is_weekend', 'is_holiday', 'month', 'year']].values.reshape(1, -1)\n",
    "        pred = model.predict(features)[0]\n",
    "    else:\n",
    "        pred = np.nan\n",
    "    predictions.append(pred)\n",
    "\n",
    "test_df['prediction'] = predictions\n",
    "\n",
    "# Save predictions to CSV\n",
    "test_df[['row_id', 'prediction']].to_csv('task2_predictions.csv', index=False)\n",
    "\n",
    "print('Predictions saved to task2_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
